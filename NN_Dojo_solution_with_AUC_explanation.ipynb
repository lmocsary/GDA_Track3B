{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Dojo_solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQPbhutEGd4F"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7tA7ZIuGhsP"
      },
      "source": [
        "Loading the dataset about breast cancer:\n",
        "\n",
        "\n",
        "*   radius (mean of distances from center to points on the perimeter)\n",
        "*   texture (standard deviation of gray-scale values)\n",
        "\n",
        "* perimeter\n",
        "\n",
        "* area\n",
        "\n",
        "* smoothness (local variation in radius lengths)\n",
        "\n",
        "* compactness (perimeter^2 / area - 1.0)\n",
        "\n",
        "* concavity (severity of concave portions of the contour)\n",
        "\n",
        "* concave points (number of concave portions of the contour)\n",
        "\n",
        "* symmetry\n",
        "\n",
        "* fractal dimension (“coastline approximation” - 1)\n",
        "\n",
        "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utxOpPt7Gj5t"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "import warnings\n",
        "warnings.simplefilter(action=\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecnfoEAeGktv"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "df = pd.DataFrame(np.c_[cancer['data'], cancer['target']],\n",
        "                            columns=np.append(cancer['feature_names'], ['target']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ovzkD1HJvz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "92deda40-73bf-4503-976f-8740aaa589aa"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0          17.99         10.38  ...                  0.11890     0.0\n",
              "1          20.57         17.77  ...                  0.08902     0.0\n",
              "2          19.69         21.25  ...                  0.08758     0.0\n",
              "3          11.42         20.38  ...                  0.17300     0.0\n",
              "4          20.29         14.34  ...                  0.07678     0.0\n",
              "..           ...           ...  ...                      ...     ...\n",
              "564        21.56         22.39  ...                  0.07115     0.0\n",
              "565        20.13         28.25  ...                  0.06637     0.0\n",
              "566        16.60         28.08  ...                  0.07820     0.0\n",
              "567        20.60         29.33  ...                  0.12400     0.0\n",
              "568         7.76         24.54  ...                  0.07039     1.0\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvXIhc6jHroe"
      },
      "source": [
        "## Data Inspection/Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVL1Pa-5Ht5u"
      },
      "source": [
        "#df.replace({'target': 1}, \"benign\", inplace=True)\n",
        "#df.replace({'target': 0}, \"malignant\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH5K2kYQixWs",
        "outputId": "77a63b2d-a74b-47c4-e8a8-1fa441469098"
      },
      "source": [
        "df['target'].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    357\n",
              "0.0    212\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfSfdKNCH-oN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a5e6a613-4c24-478a-f96d-9543e2e08049"
      },
      "source": [
        "# inspect the distribution\n",
        "\n",
        "sns.countplot(data = df, x='target')\n",
        "plt.title('Diagnosis');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVvUlEQVR4nO3dfbBddX3v8feB0E0paERiGkMUrsRvD9oSGoq02hZl2gtcbNAqhasSbKq2F+11pAxIqVAtHZ2K3IwPKL0oibU8iHqJDL1WkZZiy4ObIk+H79yoySVpeA4Rm3okePrHWufnnuTskx1O1t6H7Pdr5kzW/q2H/T3MOvvD77d+a+2RiYkJJEkC2GvQBUiSZg9DQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSABEfHpiPizQdfRTUTcFxHHDroO7flGvE9BwyAi1gHzgW3AM8D9wGrgssz8yeAqk2YXewoaJq/PzAOAlwIfBs4BLh9sSdLsMmfQBUj9lplbgDUR8RBwa0RcDPwJsCEzz4+IFwCfB15F9TfyLeAPM3MDQEQcCqwCjgRuAxJ4fma+NSIOAb4PnAF8CNgPuCQzL6r3bQEfAU6py7kGOCczxyPiIOAK4DXAT4D7gN/MzJ/UPZ0/yMxvRMTRwKeAlwP/AXwhM9/XxH8rDR97ChpamXk7sAH49e1W7QV8jqpH8RKqD95PdKz/W+B24IXAhcDbpjj8a4AAjgM+EBGjdfufAscAS4AjgKOB8+t1Z9X1zKMa6joPmGp8dyWwMjOfB7yMKlik3cKegobdvwEHdjZk5uPAlyZfR8RFwE318kuAXwGOy8wfA7dExJopjvvnmfkfwHci4jtUATAGvAV4T2Y+Uh/vz4HPAH8GPA0sAF6amWuBf+pS89PAYRFxUGY+Btz6rH5zaQr2FDTsFgJPdDZExH4R8ZmIWB8RPwBuBuZGxN7Ai4EnMnNrxy4PTnHchzqWtwL718svBtZ3rFtftwH8FbAW+PuI+F5EnNul5hVUQ0cPRMQdEXHSTn9LqUeGgoZWRPwKVSjcst2qs6iGfl5VD9H8Rt0+AmwCDoyI/Tq2X7QLb/tvVMNSk15St5GZT2XmWZn5X4DfAd4XEcdtf4DM/H+ZeRrwIqrrE9dGxM/tQg1SVw4faehExOQH/UrgbzLznojo3OQAqusIT0bEgcAFkysyc31EfBu4MCLOB5YCrwe+2uPbXwmcHxF3UF0v+ADwN3VdJwEPAN8FtlBNnd1humxEvBX4WmY+GhFP1s1Oq9VuYShomHw1IrZRfYDeD3wM+PQU2/0vqovJj1H9X/zFwMkd699CNUvocaoLzlcDe/dYw18AzwPurl9/sW4DWEx1QXsesBn4VGbeNMUxjgc+VvdW1gOn1tcvpBnz5jVphiLiauCBzLxgpxtLs5w9BWkX1dcinqC6H+G3gWVUN8NJz3mGgrTrfh74MtV9ChuAP8rMfx1sSdLu4fCRJKlwSqokqXhODx/dddddE61Wa9BlSNJzytatWx9bunTpvKnWPadDodVqMTo6uvMNJUlFu91e322dw0eSpMJQkCQVhoIkqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkwlCQZqmJbeODLkGzUNPnRWOPuYiIfam+8LxVv8+1mXlBRFwB/CbV1w0CnJGZd0XECNXXI55I9UXnZ2TmnU3VJ812I3Na/P8P/uKgy9As85IP3NPo8Zt89tE48LrM/GFE7APcEhF/V687OzOv3W77E6i+jnAx8Crg0vpfSVKfNDZ8lJkTmfnD+uU+9c90X96wDFhd73crMDciFjRVnyRpR40+JTUi9gbawGHAJzPztoj4I+CiiPgAcCNwbmaOAwuBBzt231C3bep2/PHxccbGxhqrXxoknwCsbpr83Gs0FDLzGWBJRMwFvhIRrwTeDzwE/AxwGXAO8MFnc3wfnS1pGM30c6/dbndd15fZR5n5JHATcHxmbqqHiMaBzwFH15ttBBZ17HZw3SZJ6pPGQiEi5tU9BCLiZ4HfAh6YvE5QzzY6Gbi33mUNcHpEjETEMcCWzOw6dCRJ2v2aHD5aAKyqryvsBVyTmddHxDcjYh4wAtwF/GG9/Q1U01HXUk1JfXuDtUmSptBYKGTm3cCRU7S/rsv2E8CZTdUjSdo572iWJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKuY0deCI2Be4GWjV73NtZl4QEYcCVwEvBNrA2zLzxxHRAlYDS4HHgd/LzHVN1SdJ2lGTPYVx4HWZeQSwBDg+Io4BPgJckpmHAZuBFfX2K4DNdfsl9XaSpD5qLBQycyIzf1i/3Kf+mQBeB1xbt68CTq6Xl9WvqdcfFxEjTdUnSdpRY8NHABGxN9UQ0WHAJ4HvAk9m5rZ6kw3Awnp5IfAgQGZui4gtVENMj3U7/vj4OGNjYw1VLw3W6OjooEvQLNXk516joZCZzwBLImIu8BXgF3bn8Vutln84kobOTD/32u1213V9mX2UmU8CNwG/CsyNiMkwOhjYWC9vBBYB1OufT3XBWZLUJ42FQkTMq3sIRMTPAr8FjFGFw5vqzZYD19XLa+rX1Ou/mZkTTdUnSdpRkz2FBcBNEXE3cAfw9cy8HjgHeF9ErKW6ZnB5vf3lwAvr9vcB5zZYmyRpCo1dU8jMu4Ejp2j/HnD0FO0/At7cVD2SpJ3zjmZJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkYk5TB46IRcBqYD4wAVyWmSsj4kLgHcCj9abnZeYN9T7vB1YAzwB/nJlfa6o+SdKOGgsFYBtwVmbeGREHAO2I+Hq97pLM/GjnxhFxOHAq8ArgxcA3IuLlmflMgzVKkjo0NnyUmZsy8856+SlgDFg4zS7LgKsyczwzvw+sBY5uqj5J0o6a7CkUEXEIcCRwG/Bq4N0RcTrwbarexGaqwLi1Y7cNTB8ijI+PMzY21kjN0qCNjo4OugTNUk1+7jUeChGxP/Al4L2Z+YOIuBT4ENV1hg8BFwO//2yO3Wq1/MORNHRm+rnXbre7rms0FCJiH6pA+EJmfhkgMx/uWP/XwPX1y43Aoo7dD67bJEl90tg1hYgYAS4HxjLzYx3tCzo2ewNwb728Bjg1IloRcSiwGLi9qfokSTtqsqfwauBtwD0RcVfddh5wWkQsoRo+Wge8CyAz74uIa4D7qWYunenMI0nqr8ZCITNvAUamWHXDNPtcBFzUVE2SpOl5R7MkqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkwlCQJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFUMfCuNP++Vu2pHnhYZVk1/H+ZzQ2mdvlp69etBlaJZp/9Xpgy5BGoih7ylIkn6qp1CIiBt7aZMkPbdNO3wUEfsC+wEHRcQLgJF61fOAhTvZdxGwGpgPTACXZebKiDgQuBo4BFgHnJKZmyNiBFgJnAhsBc7IzDuf5e8lSXoWdtZTeBfQBn6h/nfy5zrgEzvZdxtwVmYeDhwDnBkRhwPnAjdm5mLgxvo1wAnA4vrnncClu/zbSJJmZNqeQmauBFZGxHsy8+O7cuDM3ARsqpefiogxqt7FMuDYerNVwD8A59TtqzNzArg1IuZGxIL6OJKkPuhp9lFmfjwifo1qyGdOR3tP03Yi4hDgSOA2YH7HB/1DVMNLUAXGgx27bajbuobC+Pg4Y2NjvZTQ1ejo6Iz2155rpufWTHluqpsmz82eQiEiPg+8DLgLmJzAPUF1zWBn++4PfAl4b2b+ICLKusyciIiJXS16UqvV8g9HjfHc0mw103Oz3W53XdfrfQpHAYfXQzs9i4h9qALhC5n55br54clhoYhYADxSt28EFnXsfnDdJknqk17vU7gX+PldOXA9m+hyYCwzP9axag2wvF5eTnXRerL99IgYiYhjgC1eT5Ck/uq1p3AQcH9E3A6MTzZm5u9Ms8+rgbcB90TEXXXbecCHgWsiYgWwHjilXncD1XTUtVRTUt/e6y8hSdo9eg2FC3f1wJl5Cz+9r2F7x02x/QRw5q6+jyRp9+l19tE/Nl2IJGnwep199BTVbCOAnwH2Af49M5/XVGGSpP7rtadwwORyfQF5GdVdypKkPcguPyU1Mycy8/8A/7WBeiRJA9Tr8NEbO17uRXXfwo8aqUiSNDC9zj56fcfyNqqnmy7b7dVIkgaq12sK3jMgSUOg1+Gjg4GPU92QBvBPwP/MzA1NFSZJ6r9eLzR/juoxFC+uf75at0mS9iC9XlOYl5mdIXBFRLy3iYIkSYPTayg8HhFvBa6sX58GPN5MSZKkQel1+Oj3qR5c9xDVl968CTijoZokSQPSa0/hg8DyzNwMEBEHAh+lCgtJ0h6i157CL00GAkBmPkH19ZqSpD1Ir6GwV0S8YPJF3VPotZchSXqO6PWD/WLgXyLii/XrNwMXNVOSJGlQeuopZOZq4I3Aw/XPGzPz800WJknqv56HgDLzfuD+BmuRJA3YLj86W5K05zIUJElFYzOIIuKzwEnAI5n5yrrtQuAdwKP1Zudl5g31uvcDK4BngD/OzK81VZskaWpNTiu9AvgEsHq79ksy86OdDRFxOHAq8AqqB+59IyJenpnPNFifJGk7jQ0fZebNwBM9br4MuCozxzPz+8Ba4OimapMkTW0QN6C9OyJOB74NnFXfKb0QuLVjmw1127TGx8cZGxubUTGjo6Mz2l97rpmeWzPlualumjw3+x0KlwIfAibqfy9mBs9ParVa/uGoMZ5bmq1mem622+2u6/oaCpn58ORyRPw1cH39ciOwqGPTg+s2SVIf9XVKakQs6Hj5BuDeenkNcGpEtCLiUGAxcHs/a5MkNTsl9UrgWOCgiNgAXAAcGxFLqIaP1gHvAsjM+yLiGqo7prcBZzrzSJL6r7FQyMzTpmi+fJrtL8KH7EnSQHlHsySpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKgwFSVIxp6kDR8RngZOARzLzlXXbgcDVwCHAOuCUzNwcESPASuBEYCtwRmbe2VRtkqSpNdlTuAI4fru2c4EbM3MxcGP9GuAEYHH9807g0gbrkiR10VgoZObNwBPbNS8DVtXLq4CTO9pXZ+ZEZt4KzI2IBU3VJkmaWmPDR13Mz8xN9fJDwPx6eSHwYMd2G+q2TUxjfHycsbGxGRU0Ojo6o/2155rpuTVTnpvqpslzs9+hUGTmRERMzOQYrVbLPxw1xnNLs9VMz812u911Xb9nHz08OSxU//tI3b4RWNSx3cF1mySpj/odCmuA5fXycuC6jvbTI2IkIo4BtnQMM0mS+qTJKalXAscCB0XEBuAC4MPANRGxAlgPnFJvfgPVdNS1VFNS395UXZKk7hoLhcw8rcuq46bYdgI4s6laJEm98Y5mSVJhKEiSCkNBklQYCpKkwlCQJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpGLOIN40ItYBTwHPANsy86iIOBC4GjgEWAeckpmbB1GfJA2rQfYUXpuZSzLzqPr1ucCNmbkYuLF+LUnqo9k0fLQMWFUvrwJOHmAtkjSUBjJ8BEwAfx8RE8BnMvMyYH5mbqrXPwTM39lBxsfHGRsbm1Eho6OjM9pfe66Znlsz5bmpbpo8NwcVCq/JzI0R8SLg6xHxQOfKzJyoA2NarVbLPxw1xnNLs9VMz812u9113UCGjzJzY/3vI8BXgKOBhyNiAUD97yODqE2ShlnfQyEifi4iDphcBn4buBdYAyyvN1sOXNfv2iRp2A1i+Gg+8JWImHz/v83M/xsRdwDXRMQKYD1wygBqk6Sh1vdQyMzvAUdM0f44cFy/65Ek/dRsmpIqSRowQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkwlCQJBVzBl3A9iLieGAlsDfwvzPzwwMuSZKGxqzqKUTE3sAngROAw4HTIuLwwVYlScNjVoUCcDSwNjO/l5k/Bq4Clg24JkkaGrNt+Ggh8GDH6w3Aq7ptvHXr1sfa7fb6mb7pZae+YqaH0B6m3W4PuoTKf7ti0BVolnl095ybL+22YraFwi5ZunTpvEHXIEl7ktk2fLQRWNTx+uC6TZLUB7Otp3AHsDgiDqUKg1OB/z7YkiRpeMyqnkJmbgPeDXwNGAOuycz7BluVJA2PkYmJiUHXIEmaJWZVT0GSNFiGgiSpmG0XmtUHO3uUSES0gNXAUuBx4Pcyc12/69RwiYjPAicBj2TmK6dYP0J13p4IbAXOyMw7+1vlns+ewpDp8VEiK4DNmXkYcAnwkf5WqSF1BXD8NOtPABbXP+8ELu1DTUPHUBg+vTxKZBmwql6+Fjiu/r80qTGZeTPwxDSbLANWZ+ZEZt4KzI2IBf2pbngYCsNnqkeJLOy2TT1NeAvwwr5UJ3XXy7mrGTIUJEmFoTB8enmUSNkmIuYAz6e64CwNko/B6QNnHw2fXh4lsgZYDvwL8Cbgm5npXY4atDXAuyPiKqqnJ2/JzE0DrmmPYygMmczcFhGTjxLZG/hsZt4XER8Evp2Za4DLgc9HxFqqC3+nDq5iDYuIuBI4FjgoIjYAFwD7AGTmp4EbqKajrqWakvr2wVS6Z/MxF5KkwmsKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBWkaETE3Iv5HH97n5CkeTCj1naEgTW8u0HMoRMRIRDybv6uTqZ5aKw2U9ylI06jvnl0GJHAT8EvAC6huqjo/M6+LiEOobga8jeo7KE4ETgfeCjxK9RC3dmZ+NCJeRvXo8nlUN2C9AzgQuJ7qwYNbgN/NzO/263eUOtlTkKZ3LvDdzFwCnA28ITN/GXgtcHHHI8UXA5/KzFcALwJ+FziC6jsAjuo43mXAezJzKfAn9T7/TPUIh7Mzc4mBoEHyMRdS70aAv4yI3wB+QvXY5vn1uvX1M/4BXg1cl5k/An4UEV8FiIj9gV8DvhgRk8ds9at4qReGgtS7t1AN+yzNzKcjYh2wb73u33vYfy/gybrXIc1KDh9J03sKOKBefj7V9wc/HRGvBV7aZZ9vAa+PiH3r3sFJAJn5A+D7EfFmKBelj5jifaSBMRSkaWTm48C3IuJeYAlwVETcQ3Uh+YEu+9xBdY3gbuDvgHuoLiBD1dtYERHfAe7jp1+FehVwdkT8a30xWhoIZx9JDYiI/TPzhxGxH3Az8M7MvHPQdUk74zUFqRmX1Tej7QusMhD0XGFPQZJUeE1BklQYCpKkwlCQJBWGgiSpMBQkScV/AtY+CCKPttYiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rty_ZwMA9sqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba3e562-b9ed-415a-d42a-fcc2dc63a2d0"
      },
      "source": [
        "#inspect the data and columns\n",
        "# count number of empty values in each column\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "target                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3d3YOyYjxv4",
        "outputId": "a73e5ad5-82a2-47d4-fe55-2bdb1112f0e7"
      },
      "source": [
        "#look at the data types to see which columns need to be encoded\n",
        "df.dtypes\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                float64\n",
              "mean texture               float64\n",
              "mean perimeter             float64\n",
              "mean area                  float64\n",
              "mean smoothness            float64\n",
              "mean compactness           float64\n",
              "mean concavity             float64\n",
              "mean concave points        float64\n",
              "mean symmetry              float64\n",
              "mean fractal dimension     float64\n",
              "radius error               float64\n",
              "texture error              float64\n",
              "perimeter error            float64\n",
              "area error                 float64\n",
              "smoothness error           float64\n",
              "compactness error          float64\n",
              "concavity error            float64\n",
              "concave points error       float64\n",
              "symmetry error             float64\n",
              "fractal dimension error    float64\n",
              "worst radius               float64\n",
              "worst texture              float64\n",
              "worst perimeter            float64\n",
              "worst area                 float64\n",
              "worst smoothness           float64\n",
              "worst compactness          float64\n",
              "worst concavity            float64\n",
              "worst concave points       float64\n",
              "worst symmetry             float64\n",
              "worst fractal dimension    float64\n",
              "target                     float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egfds3xAULJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ab9dbd-0e8a-4435-8a31-b851aa7536dd"
      },
      "source": [
        "#define X and y\n",
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1]\n",
        "y\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.0\n",
              "1      0.0\n",
              "2      0.0\n",
              "3      0.0\n",
              "4      0.0\n",
              "      ... \n",
              "564    0.0\n",
              "565    0.0\n",
              "566    0.0\n",
              "567    0.0\n",
              "568    1.0\n",
              "Name: target, Length: 569, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvNTnzqJCZcf"
      },
      "source": [
        "## 1) Split the Data into Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq_mpO7LCF1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7e6bac-8c04-443b-eb70-c6d8d9c944ba"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# use random state 42\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(398, 30)\n",
            "(171, 30)\n",
            "(171,)\n",
            "(398,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEu-XQIuLfE4"
      },
      "source": [
        "# feature scaling - standardscaler\n",
        "from sklearn import preprocessing\n",
        "scaler=preprocessing.StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n",
        "\n",
        "# scaled arrays\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnDZpY7dNGV4"
      },
      "source": [
        "## Create Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKopWmrJCnK_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bssc7Ctlld8h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqhUBrRvCsS6"
      },
      "source": [
        "\n",
        "\n",
        "#adding the input and first hidden layer\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Dense(15,activation=\"relu\",input_dim=30))\n",
        "model.add(Dense(6,activation=\"relu\"))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trg8k2LwCyva"
      },
      "source": [
        "#compile the model\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAanQbf7l5Df"
      },
      "source": [
        "\n",
        "#show model summary\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjajWIPalsAp",
        "outputId": "503ff398-98a7-4d64-c055-bf82ef1014cd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 15)                465       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 96        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 568\n",
            "Trainable params: 568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-kHOxG_ImdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b934d77a-26ec-441b-e0a9-56f50b7d6a8b"
      },
      "source": [
        "# see if you can reproduce the parameters from input to hidden layer:\n",
        "\n",
        "print(X_train.shape[1] * 15 + 15)\n",
        "\n",
        "#(dimension of W_1)\n",
        "\n",
        "# first hidden to second hidden layer\n",
        "print(15 *6 +6)\n",
        "#(dimension of W_2))\n",
        "\n",
        "\n",
        "# second hidden to output layer\n",
        "print(6 * 1 +1)\n",
        "#(dimension of W_3 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "465\n",
            "96\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRVmifMsC1lS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5fdac02-8a0d-4b76-c26e-afc55a3888a3"
      },
      "source": [
        "#fit the model\n",
        "model.fit(X_train,y_train,batch_size=32,epochs=100,validation_data=(X_test,y_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 19ms/step - loss: 0.7084 - accuracy: 0.6307 - val_loss: 0.6433 - val_accuracy: 0.6550\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.6809 - val_loss: 0.5391 - val_accuracy: 0.7076\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7337 - val_loss: 0.4586 - val_accuracy: 0.7719\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7965 - val_loss: 0.3944 - val_accuracy: 0.8480\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8543 - val_loss: 0.3366 - val_accuracy: 0.9123\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3306 - accuracy: 0.9020 - val_loss: 0.2878 - val_accuracy: 0.9240\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2887 - accuracy: 0.9322 - val_loss: 0.2471 - val_accuracy: 0.9298\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2537 - accuracy: 0.9347 - val_loss: 0.2145 - val_accuracy: 0.9415\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2236 - accuracy: 0.9397 - val_loss: 0.1876 - val_accuracy: 0.9357\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1989 - accuracy: 0.9422 - val_loss: 0.1664 - val_accuracy: 0.9474\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.9472 - val_loss: 0.1502 - val_accuracy: 0.9474\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1638 - accuracy: 0.9523 - val_loss: 0.1370 - val_accuracy: 0.9474\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1506 - accuracy: 0.9573 - val_loss: 0.1260 - val_accuracy: 0.9474\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.9598 - val_loss: 0.1175 - val_accuracy: 0.9474\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1300 - accuracy: 0.9598 - val_loss: 0.1101 - val_accuracy: 0.9591\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 0.9673 - val_loss: 0.1040 - val_accuracy: 0.9591\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9698 - val_loss: 0.0983 - val_accuracy: 0.9591\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9698 - val_loss: 0.0932 - val_accuracy: 0.9649\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.9724 - val_loss: 0.0889 - val_accuracy: 0.9708\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9774 - val_loss: 0.0858 - val_accuracy: 0.9708\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0943 - accuracy: 0.9799 - val_loss: 0.0827 - val_accuracy: 0.9766\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9799 - val_loss: 0.0797 - val_accuracy: 0.9766\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9799 - val_loss: 0.0769 - val_accuracy: 0.9766\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9799 - val_loss: 0.0751 - val_accuracy: 0.9825\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9824 - val_loss: 0.0725 - val_accuracy: 0.9825\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9824 - val_loss: 0.0710 - val_accuracy: 0.9825\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9824 - val_loss: 0.0694 - val_accuracy: 0.9825\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9824 - val_loss: 0.0679 - val_accuracy: 0.9825\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9824 - val_loss: 0.0664 - val_accuracy: 0.9825\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0697 - accuracy: 0.9824 - val_loss: 0.0653 - val_accuracy: 0.9883\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9849 - val_loss: 0.0636 - val_accuracy: 0.9883\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9849 - val_loss: 0.0628 - val_accuracy: 0.9883\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9849 - val_loss: 0.0618 - val_accuracy: 0.9883\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.9849 - val_loss: 0.0610 - val_accuracy: 0.9883\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9849 - val_loss: 0.0610 - val_accuracy: 0.9883\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9849 - val_loss: 0.0598 - val_accuracy: 0.9883\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9849 - val_loss: 0.0594 - val_accuracy: 0.9883\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 0.9849 - val_loss: 0.0591 - val_accuracy: 0.9883\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9899 - val_loss: 0.0585 - val_accuracy: 0.9883\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0550 - accuracy: 0.9874 - val_loss: 0.0581 - val_accuracy: 0.9883\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9899 - val_loss: 0.0571 - val_accuracy: 0.9883\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9899 - val_loss: 0.0565 - val_accuracy: 0.9883\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9899 - val_loss: 0.0563 - val_accuracy: 0.9883\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9899 - val_loss: 0.0561 - val_accuracy: 0.9883\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0498 - accuracy: 0.9899 - val_loss: 0.0561 - val_accuracy: 0.9883\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9899 - val_loss: 0.0556 - val_accuracy: 0.9883\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9899 - val_loss: 0.0559 - val_accuracy: 0.9883\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9899 - val_loss: 0.0556 - val_accuracy: 0.9883\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9899 - val_loss: 0.0556 - val_accuracy: 0.9883\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0455 - accuracy: 0.9899 - val_loss: 0.0557 - val_accuracy: 0.9883\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9925 - val_loss: 0.0555 - val_accuracy: 0.9883\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9899 - val_loss: 0.0554 - val_accuracy: 0.9883\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9899 - val_loss: 0.0551 - val_accuracy: 0.9883\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9899 - val_loss: 0.0553 - val_accuracy: 0.9883\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9925 - val_loss: 0.0556 - val_accuracy: 0.9883\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0411 - accuracy: 0.9925 - val_loss: 0.0555 - val_accuracy: 0.9883\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 0.9925 - val_loss: 0.0560 - val_accuracy: 0.9883\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9925 - val_loss: 0.0558 - val_accuracy: 0.9883\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0391 - accuracy: 0.9925 - val_loss: 0.0561 - val_accuracy: 0.9883\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9925 - val_loss: 0.0557 - val_accuracy: 0.9883\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9925 - val_loss: 0.0563 - val_accuracy: 0.9883\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9925 - val_loss: 0.0574 - val_accuracy: 0.9883\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9925 - val_loss: 0.0575 - val_accuracy: 0.9883\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9925 - val_loss: 0.0574 - val_accuracy: 0.9883\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9925 - val_loss: 0.0572 - val_accuracy: 0.9883\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9925 - val_loss: 0.0578 - val_accuracy: 0.9883\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9925 - val_loss: 0.0574 - val_accuracy: 0.9883\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9925 - val_loss: 0.0582 - val_accuracy: 0.9883\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9925 - val_loss: 0.0584 - val_accuracy: 0.9883\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.9925 - val_loss: 0.0580 - val_accuracy: 0.9883\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9925 - val_loss: 0.0584 - val_accuracy: 0.9883\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9925 - val_loss: 0.0588 - val_accuracy: 0.9883\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9925 - val_loss: 0.0589 - val_accuracy: 0.9883\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9925 - val_loss: 0.0585 - val_accuracy: 0.9883\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9925 - val_loss: 0.0588 - val_accuracy: 0.9883\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9925 - val_loss: 0.0585 - val_accuracy: 0.9883\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9925 - val_loss: 0.0586 - val_accuracy: 0.9883\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9925 - val_loss: 0.0584 - val_accuracy: 0.9883\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9925 - val_loss: 0.0585 - val_accuracy: 0.9883\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9925 - val_loss: 0.0589 - val_accuracy: 0.9883\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9925 - val_loss: 0.0590 - val_accuracy: 0.9883\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9925 - val_loss: 0.0592 - val_accuracy: 0.9883\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.0590 - val_accuracy: 0.9883\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9925 - val_loss: 0.0587 - val_accuracy: 0.9883\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.0590 - val_accuracy: 0.9883\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 0.0591 - val_accuracy: 0.9883\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 0.0592 - val_accuracy: 0.9883\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0588 - val_accuracy: 0.9883\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0591 - val_accuracy: 0.9883\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.0589 - val_accuracy: 0.9883\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0592 - val_accuracy: 0.9883\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0594 - val_accuracy: 0.9883\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0594 - val_accuracy: 0.9883\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0593 - val_accuracy: 0.9883\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.0599 - val_accuracy: 0.9883\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 0.0597 - val_accuracy: 0.9883\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.0596 - val_accuracy: 0.9883\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.0597 - val_accuracy: 0.9883\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.0601 - val_accuracy: 0.9883\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9925 - val_loss: 0.0605 - val_accuracy: 0.9883\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa8d22ce710>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qBTMOIcFLGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d00aca-af01-41a9-d515-8c572a9ed847"
      },
      "source": [
        "#evaluate the model and save it into the variable score\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06046389415860176, 0.988304078578949]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9aygjgtJUiv"
      },
      "source": [
        "The metrics that *evaluate()* gives us depend on the input argument *metrics* that we used when setting up our NN. Keras knows several other metrics (see [Keras doc. for details](https://keras.io/metrics/)) but not all known metrics are supported for training the NN. Between, you can also extend the set of metrics with customer metrics (see this [example](https://machinelearningmastery.com/custom-metrics-deep-learning-keras-python/) if interested.).\n",
        "\n",
        "We also have access to model performance results via the result of *model.fit()*, that is our variable *story*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzrrd6XLWvXg"
      },
      "source": [
        "# Now install the tensorflow addons and define the following metrics. You have AUC,Precision and Recall in Keras Metrics but F1 you will need to get it from tensorflow addons\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPRMM0usWor3",
        "outputId": "597e18e2-d7e0-47e9-f2a0-ccee9febbf90"
      },
      "source": [
        "!pip install tensorflow-addons\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4zWF58rWmcG"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf \n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "metrics = [ \n",
        "    #keras.metrics.Precision(),\n",
        "    #keras.metrics.Recall(),\n",
        "    keras.metrics.AUC(),\n",
        "    #tfa.metrics.F1Score(\n",
        "    #    name=\"f1_micro\",\n",
        "    #    average=\"micro\",\n",
        "    #    num_classes=1,\n",
        "    #    threshold=0.5,\n",
        "    #),\n",
        "    #tfa.metrics.F1Score(\n",
        "    #    name=\"f1_weighted\",\n",
        "    #    average=\"weighted\",\n",
        "    #    num_classes=1,\n",
        "    #    threshold=0.5,\n",
        "    #),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeYiEkLjW2hE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696984fc-6e1a-44ff-f773-50fa7aac5699"
      },
      "source": [
        "# rerun the mmodel with the above defined metrics in your complie call\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy', keras.metrics.AUC()])\n",
        "\n",
        "story = model.fit(X_train,y_train,batch_size=32,epochs=100,validation_data=(X_test,y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 29ms/step - loss: 0.0224 - accuracy: 0.9925 - auc_1: 0.9999 - val_loss: 0.0609 - val_accuracy: 0.9883 - val_auc_1: 0.9902\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9883 - val_auc_1: 0.9902\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9883 - val_auc_1: 0.9902\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9825 - val_auc_1: 0.9902\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0613 - val_accuracy: 0.9883 - val_auc_1: 0.9906\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0177 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0613 - val_accuracy: 0.9883 - val_auc_1: 0.9904\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9825 - val_auc_1: 0.9907\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0167 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9825 - val_auc_1: 0.9907\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0617 - val_accuracy: 0.9825 - val_auc_1: 0.9907\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0161 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9883 - val_auc_1: 0.9907\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9942 - val_auc_1: 0.9907\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9925 - auc_1: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9825 - val_auc_1: 0.9907\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9950 - auc_1: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9825 - val_auc_1: 0.9907\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 0.9950 - auc_1: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9825 - val_auc_1: 0.9907\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9950 - auc_1: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9825 - val_auc_1: 0.9908\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9950 - auc_1: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9825 - val_auc_1: 0.9907\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9950 - auc_1: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9825 - val_auc_1: 0.9907\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9950 - auc_1: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9825 - val_auc_1: 0.9908\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9950 - auc_1: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9883 - val_auc_1: 0.9908\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0098 - accuracy: 0.9975 - auc_1: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9883 - val_auc_1: 0.9907\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9883 - val_auc_1: 0.9907\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9883 - val_auc_1: 0.9907\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9883 - val_auc_1: 0.9907\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9825 - val_auc_1: 0.9908\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9883 - val_auc_1: 0.9907\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9825 - val_auc_1: 0.9907\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9825 - val_auc_1: 0.9907\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9825 - val_auc_1: 0.9908\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9825 - val_auc_1: 0.9908\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9766 - val_auc_1: 0.9910\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9766 - val_auc_1: 0.9910\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9766 - val_auc_1: 0.9911\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9825 - val_auc_1: 0.9912\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9825 - val_auc_1: 0.9912\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9825 - val_auc_1: 0.9912\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9825 - val_auc_1: 0.9912\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9825 - val_auc_1: 0.9912\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9825 - val_auc_1: 0.9910\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9825 - val_auc_1: 0.9911\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9825 - val_auc_1: 0.9912\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9825 - val_auc_1: 0.9913\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9825 - val_auc_1: 0.9913\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9825 - val_auc_1: 0.9913\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9766 - val_auc_1: 0.9912\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9825 - val_auc_1: 0.9913\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 9.8408e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 9.6765e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 9.7880e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9766 - val_auc_1: 0.9914\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 9.6407e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.3055e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 8.8169e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 8.5101e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 8.3606e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 8.0434e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 7.8375e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 7.6491e-04 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9825 - val_auc_1: 0.9914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_DLHy3BFemk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "f6ecbe65-8982-48e7-dc6b-9f1f7ff877fc"
      },
      "source": [
        "# print Test Loss and Accuracy and plot the history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_history(story):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18.5, 10.5)\n",
        "    ax1.plot(story.history['accuracy'])\n",
        "    ax1.plot(story.history['val_accuracy'])\n",
        "    ax1.set(xlabel='epoch', ylabel='accuracy')\n",
        "    ax1.legend(['train_accuracy', 'val_accuracy'], loc='best')\n",
        "    ax1.set_title('Accuracy evolution during NN training')\n",
        "    \n",
        "    ax2.plot(story.history['loss'])\n",
        "    ax2.plot(story.history['val_loss'])\n",
        "    ax2.set(xlabel='epoch', ylabel='loss')\n",
        "    ax2.legend(['train_loss', 'val_loss'], loc='best')\n",
        "    ax2.set_title('Loss evolution during NN training')\n",
        "    plt.show()\n",
        "\n",
        "show_history(story)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1332x756 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ4AwjONFbRV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JOpM-jmuO-W"
      },
      "source": [
        "Typically validation loss should be similar to but slightly higher than training loss. As long as validation loss is lower than or even equal to training loss one should keep doing more training. If training loss is reducing without increase in validation loss then again keep doing more training. If validation loss starts increasing then it is time to stop. Some over-fitting is nearly always a good thing. All that matters in the end is: is the validation loss as low as you can get it!\n",
        "\n",
        "If overall accuracy still not acceptable then review mistakes model is making and think of what can one change: More data? More / different data augmentations? Different architecture?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXFMSTVhJh02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4712accd-0f23-4bb4-cdca-95007eaaa9bb"
      },
      "source": [
        "# Compute predictions of X_test\n",
        "yhat = model.predict(X_test)\n",
        "yhat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9905062e-01],\n",
              "       [5.6225968e-18],\n",
              "       [1.6278195e-12],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [0.0000000e+00],\n",
              "       [6.6331809e-33],\n",
              "       [2.8600146e-08],\n",
              "       [7.5968850e-01],\n",
              "       [1.0000000e+00],\n",
              "       [6.4316201e-01],\n",
              "       [2.0022181e-08],\n",
              "       [9.9999940e-01],\n",
              "       [1.8524943e-08],\n",
              "       [1.0000000e+00],\n",
              "       [1.2428638e-16],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.6285921e-24],\n",
              "       [9.9999797e-01],\n",
              "       [1.0000000e+00],\n",
              "       [2.9735537e-34],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999917e-01],\n",
              "       [1.0000000e+00],\n",
              "       [3.3270953e-21],\n",
              "       [9.9999982e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [8.5101724e-03],\n",
              "       [9.9999928e-01],\n",
              "       [2.2839539e-16],\n",
              "       [9.9966800e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.9290015e-13],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9995244e-01],\n",
              "       [9.9693298e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9995780e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.0854814e-15],\n",
              "       [1.1833256e-27],\n",
              "       [8.0128312e-01],\n",
              "       [3.4332579e-01],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999958e-01],\n",
              "       [1.0000000e+00],\n",
              "       [0.0000000e+00],\n",
              "       [3.7690286e-06],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.8282539e-26],\n",
              "       [1.9065833e-31],\n",
              "       [9.9911761e-01],\n",
              "       [1.0000000e+00],\n",
              "       [9.9979562e-01],\n",
              "       [7.5121212e-22],\n",
              "       [0.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999428e-01],\n",
              "       [7.9987227e-13],\n",
              "       [9.0279563e-13],\n",
              "       [1.0000000e+00],\n",
              "       [2.3294142e-12],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999511e-01],\n",
              "       [6.7949623e-02],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [3.4038580e-10],\n",
              "       [1.0000000e+00],\n",
              "       [2.8935075e-04],\n",
              "       [1.2030083e-31],\n",
              "       [6.6735197e-08],\n",
              "       [2.1802360e-17],\n",
              "       [5.3479868e-14],\n",
              "       [1.4728381e-16],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [7.4778926e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [2.0181787e-20],\n",
              "       [9.5080908e-24],\n",
              "       [1.0000000e+00],\n",
              "       [1.2335653e-13],\n",
              "       [4.7177284e-10],\n",
              "       [1.0000000e+00],\n",
              "       [3.2542893e-22],\n",
              "       [3.3681482e-15],\n",
              "       [9.9997848e-01],\n",
              "       [9.9728614e-01],\n",
              "       [1.0000000e+00],\n",
              "       [7.5127345e-34],\n",
              "       [9.9999696e-01],\n",
              "       [9.9992049e-01],\n",
              "       [8.7398540e-13],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999535e-01],\n",
              "       [3.0247355e-36],\n",
              "       [1.0917243e-01],\n",
              "       [5.1630054e-35],\n",
              "       [1.0000000e+00],\n",
              "       [9.9699700e-01],\n",
              "       [1.0000000e+00],\n",
              "       [7.2186245e-17],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999976e-01],\n",
              "       [6.4015189e-18],\n",
              "       [9.9981725e-01],\n",
              "       [9.5143991e-25],\n",
              "       [5.1808908e-16],\n",
              "       [9.9999982e-01],\n",
              "       [1.0000000e+00],\n",
              "       [5.4031229e-23],\n",
              "       [9.2308460e-35],\n",
              "       [1.5162931e-20],\n",
              "       [9.9999237e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.3745765e-15],\n",
              "       [9.8171198e-01],\n",
              "       [1.0000000e+00],\n",
              "       [7.8004384e-01],\n",
              "       [5.4497981e-13],\n",
              "       [1.0000000e+00],\n",
              "       [1.3684611e-29],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [2.5440565e-11],\n",
              "       [1.0000000e+00],\n",
              "       [7.0165130e-20],\n",
              "       [1.2415710e-22],\n",
              "       [7.6179000e-05],\n",
              "       [1.0000000e+00],\n",
              "       [4.4889712e-05],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999857e-01],\n",
              "       [9.9999940e-01],\n",
              "       [0.0000000e+00],\n",
              "       [1.2579501e-17],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [3.6291480e-03],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9200356e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.3174428e-10],\n",
              "       [1.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32rVq2dmK76Q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YLpHjipKbZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162f4ffb-8194-4b5b-a6cc-24e941ad6f80"
      },
      "source": [
        "# Finding the most probable class\n",
        "yhat_c = (yhat > 0.5)\n",
        "print(yhat_c)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttv8CTL9J2u9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ae3d60-f337-4d39-e370-0d0be048b838"
      },
      "source": [
        "# print the confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "cm = confusion_matrix(y_test,yhat_c)\n",
        "score = accuracy_score(y_test,yhat_c)\n",
        "auc = roc_auc_score(y_test,yhat)\n",
        "print(cm)\n",
        "print('accuracy is:',score)\n",
        "print('auc is:',auc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 62   1]\n",
            " [  2 106]]\n",
            "accuracy is: 0.9824561403508771\n",
            "auc is: 0.9961787184009406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "nxgMUvfHI3sP",
        "outputId": "067f23f0-cf57-47f2-e808-4b22c952c97b"
      },
      "source": [
        "import seaborn as sn\n",
        "sn.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa8d22712d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y_9kW-HNogg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01615040-1cab-4c70-e136-cad748f4b359"
      },
      "source": [
        " #print calssification report\n",
        " from sklearn.metrics import classification_report\n",
        "\n",
        " print(classification_report(y_test, yhat_c))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.98      0.98        63\n",
            "         1.0       0.99      0.98      0.99       108\n",
            "\n",
            "    accuracy                           0.98       171\n",
            "   macro avg       0.98      0.98      0.98       171\n",
            "weighted avg       0.98      0.98      0.98       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln13cS9ZL6WB"
      },
      "source": [
        "https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liJvfoxrHkgr"
      },
      "source": [
        "Ok that worked out. Now remember that we were rather critical with classification accuracy in the lecture. Let's revisit why we do not like this measure.\n",
        "\n",
        "Classification accuracy is a threshold metric. It calculates model performance for one threshold or classification cut-off. If not specified, this threshold is usually set to 0.5.  However that is not what we necessarily want in an unbalanced case.\n",
        "\n",
        "A preferable approach to assess classification performance is to consider all possible thresholds. This is what receiver-operating-characteristics (ROC) analysis does. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXoLyU0hIhvM"
      },
      "source": [
        "Classification accuracy simply calculates the number of correct class predictions (main diagonal) over all cases. Correct predictions are twofold. We can classify a good customer as good customer and we can classify a bad customer as bad customer. Likewise, our classifier can make two errors, classifying an actually good customer as bad and classifying an actually bad customer as good. We find the numbers of these errors in the off-diagonal of the confusion matrix. Which class a model predicts depends on the classification threshold. You classify cases as BAD if $p(y=BAD|x) \\gt \\tau$, and as GOOD otherwise, whereby $\\tau$ denotes the threshold. \n",
        "\n",
        "Hence, the above **confusion table is based on one threshold**. It might look rather different for another threshold. A ROC curve considers all cut-offs $\\tau \\in [0,1]$ plotting the **True Positive Rate** and **False Positive Rate** for each threshold. Given that ROC analysis is a general tool for binary classification, and used in various domains, people came up with a standardized terminology to refer to the classes. Instead of speaking about goods and bads (i.e., credit scoring jargon) or zeros and ones (which is likely to offend members of the former group), we refer to the classes as the *positive* and the *negative* class. Thus, the TPR is the fraction cases that the classifier predicts to be of class positive, and that actually belong to that class. The true negative rate or TNR is defined alike. For the two errors we have the false positive rate (FPR) and the false negative rate (FNR). Correct interpretation of these errors is maybe a little difficult. How about false positives? The classifier predicts class positive but the prediction is false. Such a case actually belongs to the negative class. So the FPR is the fraction of cases that the classifier predicts as positives and that actually are negatives. The same argumentation goes for the FNR.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEexjuunJbu0"
      },
      "source": [
        "## ROC Curve and AUC\n",
        "This is one of the most important evaluation metrics in classification analysis. Have a look at the graph below. The curve tells us how well the model differentiates the two classes, in regards to their predicted probabilities. A ROC curve has the FPR on the X-axis and TPR on the Y-axis. The curve is derived from all the different combinations of TPR and FPR (i.e., confusion tables) across all possible thresholds  0≤𝜏≤1  (assuming we have probabilistic predictions).\n",
        "\n",
        "The AUC stand for the area under the curve and is a ranking indicator. The AUC estimates the probability that a randomly chosen positive instance is correctly ranked higher than a randomly chosen negative (Hanley and McNeil, 1983). We calculate this area, as our goal is to have a FPR of 0 and a TPR of 1. This would be the perfect model. This point is in the top right corner of a ROC Curve. So the closer we get to that point, the better the model and the bigger the area under it. It is common practice to add a horizontal line to the plot. You can show that this line corresponds to a random classifier. So any serious model should give a ROC curve (much) above the horizontal line. This also implies that a classifier should display AUC (much) bigger than 0.5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCPl_Ed-JY3a"
      },
      "source": [
        "## ROC Curve and AUC\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
        "\n",
        "\n",
        "fpr , tpr , thresholds = roc_curve( y_test , yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "-Zr-oBshLIYs",
        "outputId": "2b357714-fb71-4470-e0fa-c0071ef23c3a"
      },
      "source": [
        "def plot_roc_curve(fpr,tpr): \n",
        "  plt.plot(fpr,tpr) \n",
        "  #plt.axis([0,1,0,1]) \n",
        "  plt.xlabel('False Positive Rate') \n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC curve of NN model')\n",
        "  plt.plot([0, 1], [0, 1], \"r--\");  # the random benchmark we need to add manually  \n",
        "  plt.show()    \n",
        "  \n",
        "plot_roc_curve (fpr,tpr)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONzmU-fzLi5U",
        "outputId": "b4629535-d78f-4856-c97e-12e7f768a824"
      },
      "source": [
        "# get the best threshold for the NN model\n",
        "J = tpr - fpr\n",
        "ix = np.argmax(J)\n",
        "best_thresh = thresholds[ix]\n",
        "print('Best Threshold NN model=%f' % (best_thresh))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold NN model=0.109172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwPRM0dZL_Kh"
      },
      "source": [
        "# Finding the most probable class based on the optimal threshold\n",
        "yhat_c_optimal = (yhat > 0.109172)\n",
        "print(yhat_c_optimal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn9N2fffMTsD",
        "outputId": "96953423-f7e1-435d-825e-519c8b39cbfd"
      },
      "source": [
        " print(classification_report(y_test, yhat_c_optimal))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.98      0.99        63\n",
            "         1.0       0.99      1.00      1.00       108\n",
            "\n",
            "    accuracy                           0.99       171\n",
            "   macro avg       1.00      0.99      0.99       171\n",
            "weighted avg       0.99      0.99      0.99       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHevi-RGNJW8",
        "outputId": "ce014293-cc9e-44a5-b3db-1e6de86d5abf"
      },
      "source": [
        "cm_optimal = confusion_matrix(y_test,yhat_c_optimal)\n",
        "score_optimal = accuracy_score(y_test,yhat_c_optimal)\n",
        "auc_optimal = roc_auc_score(y_test,yhat)\n",
        "print(cm_optimal)\n",
        "print('accuracy is:',score_optimal)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 62   1]\n",
            " [  0 108]]\n",
            "accuracy is: 0.9941520467836257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l0Wu5DMbQDI"
      },
      "source": [
        "\n",
        "# OPTION 2\n",
        "Lets implement the same model with softmax output activation and 2 nodes. REMEMBER, the binary classification case is a special case of the multiclass classification case with 2 classes. so the softmax function with only 2 classes will give the sigmoid function. \n",
        "MEaning, when you have a binary classification problem, have 2 options\n",
        "1.  output activation sigmoid, 1 node and binary_crossentropy loss\n",
        "2. output activation softmax, 2 nodes and categorical_crossentropy loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8emx5bGaHoc",
        "outputId": "35db0392-4e88-4e22-8893-ee360a3fcdef"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "# Prepare the target variable\n",
        "\n",
        "# if you use categorical crossentropy loss, you have to reshape the target variable to the dimension of the classes,\n",
        "# ie. OneHot encode the Target\n",
        "# Note: you can leave the target as normal integers, but then you have to use 'sparse_categorical_crossentropy' loss\n",
        "dummy_y = np_utils.to_categorical(y)\n",
        "dummy_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pem2hXWcafVj",
        "outputId": "38eea5e8-7476-4940-e6ba-2823c49b342e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# use random state 42\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,dummy_y,test_size=0.3,random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(398, 30)\n",
            "(171, 30)\n",
            "(171, 2)\n",
            "(398, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PI5IWC4apTM"
      },
      "source": [
        "# feature scaling - standardscaler\n",
        "from sklearn import preprocessing\n",
        "scaler=preprocessing.StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n",
        "\n",
        "# scaled arrays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8dJ82XAAQ9f"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(15,activation=\"relu\",input_dim=30))\n",
        "model.add(Dense(6,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcKPmuaTX06e"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg_AkIw9YMAm",
        "outputId": "e8f3ae3b-4787-40ba-99a9-8d2dfe55f53c"
      },
      "source": [
        "#fit the model\n",
        "model.fit(X_train,y_train,batch_size=32,epochs=100,validation_data=(X_test,y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 20ms/step - loss: 0.6392 - accuracy: 0.5729 - val_loss: 0.5941 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.7990 - val_loss: 0.4885 - val_accuracy: 0.8480\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8819 - val_loss: 0.3980 - val_accuracy: 0.9006\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3638 - accuracy: 0.9045 - val_loss: 0.3260 - val_accuracy: 0.9298\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3086 - accuracy: 0.9271 - val_loss: 0.2699 - val_accuracy: 0.9415\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2677 - accuracy: 0.9397 - val_loss: 0.2270 - val_accuracy: 0.9474\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2369 - accuracy: 0.9422 - val_loss: 0.1960 - val_accuracy: 0.9532\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2145 - accuracy: 0.9472 - val_loss: 0.1729 - val_accuracy: 0.9649\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1968 - accuracy: 0.9523 - val_loss: 0.1553 - val_accuracy: 0.9649\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1818 - accuracy: 0.9573 - val_loss: 0.1410 - val_accuracy: 0.9708\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1692 - accuracy: 0.9598 - val_loss: 0.1294 - val_accuracy: 0.9708\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1587 - accuracy: 0.9623 - val_loss: 0.1193 - val_accuracy: 0.9708\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1478 - accuracy: 0.9623 - val_loss: 0.1122 - val_accuracy: 0.9708\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1379 - accuracy: 0.9623 - val_loss: 0.1065 - val_accuracy: 0.9708\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.9648 - val_loss: 0.1015 - val_accuracy: 0.9708\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9673 - val_loss: 0.0961 - val_accuracy: 0.9708\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.9724 - val_loss: 0.0912 - val_accuracy: 0.9649\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.9724 - val_loss: 0.0871 - val_accuracy: 0.9766\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9774 - val_loss: 0.0838 - val_accuracy: 0.9766\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9799 - val_loss: 0.0810 - val_accuracy: 0.9766\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9799 - val_loss: 0.0787 - val_accuracy: 0.9766\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9799 - val_loss: 0.0769 - val_accuracy: 0.9708\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9799 - val_loss: 0.0765 - val_accuracy: 0.9708\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0795 - accuracy: 0.9799 - val_loss: 0.0758 - val_accuracy: 0.9708\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9824 - val_loss: 0.0733 - val_accuracy: 0.9708\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9824 - val_loss: 0.0722 - val_accuracy: 0.9708\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9824 - val_loss: 0.0715 - val_accuracy: 0.9708\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0700 - accuracy: 0.9824 - val_loss: 0.0709 - val_accuracy: 0.9708\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9708\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9874 - val_loss: 0.0693 - val_accuracy: 0.9708\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.9874 - val_loss: 0.0687 - val_accuracy: 0.9708\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9874 - val_loss: 0.0677 - val_accuracy: 0.9708\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9874 - val_loss: 0.0663 - val_accuracy: 0.9708\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9874 - val_loss: 0.0666 - val_accuracy: 0.9708\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9874 - val_loss: 0.0667 - val_accuracy: 0.9708\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9874 - val_loss: 0.0660 - val_accuracy: 0.9708\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9874 - val_loss: 0.0642 - val_accuracy: 0.9766\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 0.9874 - val_loss: 0.0648 - val_accuracy: 0.9766\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9874 - val_loss: 0.0638 - val_accuracy: 0.9708\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9874 - val_loss: 0.0630 - val_accuracy: 0.9708\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9874 - val_loss: 0.0627 - val_accuracy: 0.9708\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9874 - val_loss: 0.0618 - val_accuracy: 0.9708\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0518 - accuracy: 0.9874 - val_loss: 0.0625 - val_accuracy: 0.9708\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9874 - val_loss: 0.0613 - val_accuracy: 0.9708\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0496 - accuracy: 0.9874 - val_loss: 0.0613 - val_accuracy: 0.9708\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0489 - accuracy: 0.9874 - val_loss: 0.0607 - val_accuracy: 0.9708\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9874 - val_loss: 0.0613 - val_accuracy: 0.9708\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0471 - accuracy: 0.9874 - val_loss: 0.0612 - val_accuracy: 0.9708\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9874 - val_loss: 0.0603 - val_accuracy: 0.9708\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9874 - val_loss: 0.0592 - val_accuracy: 0.9708\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9874 - val_loss: 0.0591 - val_accuracy: 0.9708\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9874 - val_loss: 0.0590 - val_accuracy: 0.9708\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9874 - val_loss: 0.0588 - val_accuracy: 0.9708\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9874 - val_loss: 0.0590 - val_accuracy: 0.9708\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9874 - val_loss: 0.0586 - val_accuracy: 0.9708\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.0579 - val_accuracy: 0.9708\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9874 - val_loss: 0.0573 - val_accuracy: 0.9708\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0582 - val_accuracy: 0.9708\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9899 - val_loss: 0.0579 - val_accuracy: 0.9708\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 0.9925 - val_loss: 0.0577 - val_accuracy: 0.9708\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9925 - val_loss: 0.0590 - val_accuracy: 0.9708\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9925 - val_loss: 0.0590 - val_accuracy: 0.9708\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9925 - val_loss: 0.0578 - val_accuracy: 0.9708\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9925 - val_loss: 0.0594 - val_accuracy: 0.9708\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9950 - val_loss: 0.0590 - val_accuracy: 0.9708\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9950 - val_loss: 0.0587 - val_accuracy: 0.9708\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 0.9950 - val_loss: 0.0595 - val_accuracy: 0.9708\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9950 - val_loss: 0.0600 - val_accuracy: 0.9708\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9950 - val_loss: 0.0594 - val_accuracy: 0.9708\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9950 - val_loss: 0.0585 - val_accuracy: 0.9708\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 0.9950 - val_loss: 0.0572 - val_accuracy: 0.9708\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9950 - val_loss: 0.0577 - val_accuracy: 0.9708\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9950 - val_loss: 0.0589 - val_accuracy: 0.9708\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0285 - accuracy: 0.9950 - val_loss: 0.0580 - val_accuracy: 0.9708\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9950 - val_loss: 0.0570 - val_accuracy: 0.9708\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9950 - val_loss: 0.0572 - val_accuracy: 0.9708\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9950 - val_loss: 0.0575 - val_accuracy: 0.9708\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 0.9950 - val_loss: 0.0580 - val_accuracy: 0.9708\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 0.9950 - val_loss: 0.0596 - val_accuracy: 0.9708\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9950 - val_loss: 0.0593 - val_accuracy: 0.9708\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9950 - val_loss: 0.0620 - val_accuracy: 0.9708\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0235 - accuracy: 0.9950 - val_loss: 0.0625 - val_accuracy: 0.9708\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9950 - val_loss: 0.0625 - val_accuracy: 0.9708\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9950 - val_loss: 0.0637 - val_accuracy: 0.9708\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9950 - val_loss: 0.0633 - val_accuracy: 0.9708\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0213 - accuracy: 0.9950 - val_loss: 0.0638 - val_accuracy: 0.9708\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.9950 - val_loss: 0.0629 - val_accuracy: 0.9708\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.0640 - val_accuracy: 0.9708\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.9950 - val_loss: 0.0652 - val_accuracy: 0.9708\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.0664 - val_accuracy: 0.9708\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.0671 - val_accuracy: 0.9708\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.0656 - val_accuracy: 0.9708\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.0694 - val_accuracy: 0.9708\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.0687 - val_accuracy: 0.9708\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.0702 - val_accuracy: 0.9708\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.0699 - val_accuracy: 0.9708\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.0694 - val_accuracy: 0.9708\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.0685 - val_accuracy: 0.9708\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0690 - val_accuracy: 0.9708\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0710 - val_accuracy: 0.9708\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08339faed0>"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_qbPYocYlzT",
        "outputId": "fb165302-f6cb-4b0b-b69a-5645b6d6f44d"
      },
      "source": [
        "# Compute predictions of X_test, here it is a 2 dimensional array: for each datapoint we get the probability of \n",
        "# it belonging to class 0 and to class 1. Note: compare the output to the previous yhat. Previously with 1 output neuron, \n",
        "#we got the prob only for class 1.  \n",
        "yhat = model.predict(X_test)\n",
        "yhat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.95391849e-02, 9.80460823e-01],\n",
              "       [1.00000000e+00, 4.18655692e-12],\n",
              "       [1.00000000e+00, 1.47374335e-08],\n",
              "       [6.29030546e-05, 9.99937057e-01],\n",
              "       [9.27261226e-06, 9.99990702e-01],\n",
              "       [1.00000000e+00, 6.60413752e-28],\n",
              "       [1.00000000e+00, 6.54429515e-22],\n",
              "       [9.99932170e-01, 6.77804637e-05],\n",
              "       [7.57163405e-01, 2.42836580e-01],\n",
              "       [4.34116737e-05, 9.99956608e-01],\n",
              "       [4.24893051e-02, 9.57510769e-01],\n",
              "       [9.99961972e-01, 3.80745587e-05],\n",
              "       [1.54742191e-03, 9.98452544e-01],\n",
              "       [9.99711096e-01, 2.88920564e-04],\n",
              "       [3.23613858e-05, 9.99967694e-01],\n",
              "       [9.99999166e-01, 8.16380066e-07],\n",
              "       [6.33589661e-05, 9.99936581e-01],\n",
              "       [4.51023652e-06, 9.99995470e-01],\n",
              "       [5.50071718e-07, 9.99999404e-01],\n",
              "       [1.00000000e+00, 3.45875607e-16],\n",
              "       [3.04132774e-02, 9.69586670e-01],\n",
              "       [2.48600822e-03, 9.97514009e-01],\n",
              "       [1.00000000e+00, 1.00184445e-22],\n",
              "       [1.08735039e-04, 9.99891281e-01],\n",
              "       [3.48434638e-04, 9.99651551e-01],\n",
              "       [1.90698302e-05, 9.99980927e-01],\n",
              "       [2.14848878e-05, 9.99978542e-01],\n",
              "       [1.39737350e-03, 9.98602688e-01],\n",
              "       [9.56545409e-04, 9.99043405e-01],\n",
              "       [1.00000000e+00, 6.49482977e-14],\n",
              "       [2.52377969e-04, 9.99747574e-01],\n",
              "       [1.39559434e-05, 9.99986053e-01],\n",
              "       [2.19948997e-04, 9.99780118e-01],\n",
              "       [9.02043481e-04, 9.99097943e-01],\n",
              "       [3.04042442e-05, 9.99969602e-01],\n",
              "       [1.26939500e-04, 9.99873042e-01],\n",
              "       [9.81027842e-01, 1.89722329e-02],\n",
              "       [1.04889681e-04, 9.99895096e-01],\n",
              "       [1.00000000e+00, 1.75126039e-10],\n",
              "       [1.51744848e-02, 9.84825552e-01],\n",
              "       [2.48255856e-05, 9.99975204e-01],\n",
              "       [1.00000000e+00, 2.74092322e-08],\n",
              "       [4.58079230e-05, 9.99954224e-01],\n",
              "       [2.40658032e-04, 9.99759376e-01],\n",
              "       [4.50532250e-02, 9.54946816e-01],\n",
              "       [1.72265675e-02, 9.82773423e-01],\n",
              "       [3.87590035e-06, 9.99996066e-01],\n",
              "       [1.91255391e-03, 9.98087466e-01],\n",
              "       [1.31193697e-02, 9.86880660e-01],\n",
              "       [2.35785083e-05, 9.99976397e-01],\n",
              "       [1.00000000e+00, 1.15316472e-10],\n",
              "       [1.00000000e+00, 6.96645618e-19],\n",
              "       [3.12099338e-01, 6.87900662e-01],\n",
              "       [4.45554182e-02, 9.55444634e-01],\n",
              "       [1.27331268e-05, 9.99987245e-01],\n",
              "       [6.74696348e-04, 9.99325275e-01],\n",
              "       [2.79546894e-05, 9.99971986e-01],\n",
              "       [1.00000000e+00, 9.56274195e-28],\n",
              "       [9.99948621e-01, 5.13879386e-05],\n",
              "       [2.81810321e-06, 9.99997139e-01],\n",
              "       [1.43500802e-03, 9.98565018e-01],\n",
              "       [1.00000000e+00, 3.17899638e-17],\n",
              "       [1.00000000e+00, 4.41519042e-21],\n",
              "       [2.59109512e-02, 9.74089026e-01],\n",
              "       [4.29679436e-04, 9.99570310e-01],\n",
              "       [9.19748768e-02, 9.08025086e-01],\n",
              "       [1.00000000e+00, 1.06546589e-14],\n",
              "       [1.00000000e+00, 3.68806371e-26],\n",
              "       [3.41961073e-04, 9.99657989e-01],\n",
              "       [1.07255392e-03, 9.98927414e-01],\n",
              "       [9.99999881e-01, 1.46678943e-07],\n",
              "       [1.00000000e+00, 4.53543336e-08],\n",
              "       [6.09132461e-04, 9.99390841e-01],\n",
              "       [1.00000000e+00, 2.26948114e-08],\n",
              "       [8.43629605e-05, 9.99915600e-01],\n",
              "       [2.09215970e-04, 9.99790847e-01],\n",
              "       [2.82574054e-02, 9.71742630e-01],\n",
              "       [9.53848064e-01, 4.61519510e-02],\n",
              "       [3.66570839e-06, 9.99996305e-01],\n",
              "       [1.43915982e-04, 9.99856114e-01],\n",
              "       [9.99999762e-01, 2.76952505e-07],\n",
              "       [1.06674270e-05, 9.99989390e-01],\n",
              "       [9.74740863e-01, 2.52591204e-02],\n",
              "       [1.00000000e+00, 3.26636721e-21],\n",
              "       [9.99939561e-01, 6.04320194e-05],\n",
              "       [1.00000000e+00, 4.14305153e-11],\n",
              "       [1.00000000e+00, 9.27604348e-13],\n",
              "       [1.00000000e+00, 3.61022723e-09],\n",
              "       [2.82148576e-05, 9.99971747e-01],\n",
              "       [1.26368040e-03, 9.98736322e-01],\n",
              "       [8.73688201e-04, 9.99126375e-01],\n",
              "       [8.52892697e-01, 1.47107333e-01],\n",
              "       [7.78848818e-03, 9.92211580e-01],\n",
              "       [3.08046612e-04, 9.99691963e-01],\n",
              "       [1.59553092e-04, 9.99840379e-01],\n",
              "       [1.67822891e-05, 9.99983191e-01],\n",
              "       [1.00000000e+00, 1.76651188e-13],\n",
              "       [1.00000000e+00, 1.25787397e-16],\n",
              "       [1.58948728e-06, 9.99998450e-01],\n",
              "       [9.99999881e-01, 6.60586679e-08],\n",
              "       [9.99998808e-01, 1.15400189e-06],\n",
              "       [5.62393403e-08, 1.00000000e+00],\n",
              "       [1.00000000e+00, 2.79241165e-14],\n",
              "       [1.00000000e+00, 1.15220899e-09],\n",
              "       [2.09726710e-02, 9.79027390e-01],\n",
              "       [1.86698303e-01, 8.13301682e-01],\n",
              "       [1.77869899e-03, 9.98221338e-01],\n",
              "       [1.00000000e+00, 6.33368772e-22],\n",
              "       [2.16883700e-03, 9.97831166e-01],\n",
              "       [3.59639414e-02, 9.64036047e-01],\n",
              "       [1.00000000e+00, 1.33925058e-08],\n",
              "       [1.18157259e-04, 9.99881864e-01],\n",
              "       [1.14221452e-02, 9.88577843e-01],\n",
              "       [1.00000000e+00, 5.36160477e-24],\n",
              "       [9.87473965e-01, 1.25260865e-02],\n",
              "       [1.00000000e+00, 6.31862281e-24],\n",
              "       [5.18248441e-07, 9.99999523e-01],\n",
              "       [4.55899052e-02, 9.54410076e-01],\n",
              "       [1.69280156e-05, 9.99983072e-01],\n",
              "       [1.00000000e+00, 1.85853177e-12],\n",
              "       [1.60839912e-02, 9.83915985e-01],\n",
              "       [2.59260614e-05, 9.99974132e-01],\n",
              "       [4.95548244e-04, 9.99504447e-01],\n",
              "       [1.00000000e+00, 7.53141716e-11],\n",
              "       [1.64138675e-02, 9.83586133e-01],\n",
              "       [1.00000000e+00, 5.03439961e-16],\n",
              "       [1.00000000e+00, 2.36182410e-11],\n",
              "       [2.02140058e-04, 9.99797881e-01],\n",
              "       [1.44348349e-04, 9.99855638e-01],\n",
              "       [1.00000000e+00, 1.70532593e-15],\n",
              "       [1.00000000e+00, 1.27704472e-23],\n",
              "       [1.00000000e+00, 2.22219441e-17],\n",
              "       [1.97522994e-03, 9.98024821e-01],\n",
              "       [2.96221318e-04, 9.99703705e-01],\n",
              "       [2.11383076e-03, 9.97886121e-01],\n",
              "       [1.00000000e+00, 4.45346121e-10],\n",
              "       [3.81489962e-01, 6.18510067e-01],\n",
              "       [1.79960299e-03, 9.98200417e-01],\n",
              "       [7.97934532e-02, 9.20206487e-01],\n",
              "       [1.00000000e+00, 1.30907740e-09],\n",
              "       [1.20689324e-03, 9.98793125e-01],\n",
              "       [1.00000000e+00, 4.08237543e-19],\n",
              "       [5.79273149e-07, 9.99999404e-01],\n",
              "       [6.34587309e-07, 9.99999404e-01],\n",
              "       [1.00000000e+00, 7.61408625e-09],\n",
              "       [5.42144553e-05, 9.99945760e-01],\n",
              "       [1.00000000e+00, 2.91181772e-14],\n",
              "       [1.00000000e+00, 9.54421902e-15],\n",
              "       [9.97149885e-01, 2.85013323e-03],\n",
              "       [7.52795677e-05, 9.99924660e-01],\n",
              "       [9.99625802e-01, 3.74164083e-04],\n",
              "       [7.03236356e-06, 9.99992967e-01],\n",
              "       [2.78023748e-07, 9.99999762e-01],\n",
              "       [1.09517444e-02, 9.89048302e-01],\n",
              "       [4.24238067e-04, 9.99575794e-01],\n",
              "       [1.00000000e+00, 2.71102724e-34],\n",
              "       [1.00000000e+00, 1.31949243e-10],\n",
              "       [3.30305484e-05, 9.99966979e-01],\n",
              "       [1.14405586e-03, 9.98855948e-01],\n",
              "       [1.44374064e-06, 9.99998569e-01],\n",
              "       [7.81789204e-05, 9.99921799e-01],\n",
              "       [7.35737149e-06, 9.99992609e-01],\n",
              "       [5.99520972e-05, 9.99940038e-01],\n",
              "       [1.21352205e-04, 9.99878645e-01],\n",
              "       [9.40215588e-01, 5.97844608e-02],\n",
              "       [3.91914509e-05, 9.99960780e-01],\n",
              "       [4.75046400e-05, 9.99952435e-01],\n",
              "       [3.39292079e-01, 6.60707891e-01],\n",
              "       [1.62223532e-05, 9.99983788e-01],\n",
              "       [9.99992251e-01, 7.68989503e-06],\n",
              "       [1.95542088e-04, 9.99804437e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQX8vT_Ba7Oo",
        "outputId": "86937fb0-0def-4867-c017-b34c33f42e5d"
      },
      "source": [
        "# Finding the most probable class\n",
        "yhat_c = np.argmax(yhat, axis=1)\n",
        "print(yhat_c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
            " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0\n",
            " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN4rFkDaf6ra",
        "outputId": "f03a3662-bf6c-4d4d-dd83-0a845af719d9"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(171, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN-k2DKagSS0"
      },
      "source": [
        "true_label = np.argmax(y_test,axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySv8R9k8eCMG",
        "outputId": "66f9873e-248c-42a5-81d0-11f069d0047c"
      },
      "source": [
        "\n",
        "cm = confusion_matrix(true_label,yhat_c)\n",
        "\n",
        "score = accuracy_score(true_label,yhat_c)\n",
        "print(cm)\n",
        "print('score is:',score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 62   1]\n",
            " [  0 108]]\n",
            "score is: 0.9941520467836257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7haMDK_gbaX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psLQ4es7gtzA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}