{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Dojo_solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQPbhutEGd4F"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7tA7ZIuGhsP"
      },
      "source": [
        "Loading the dataset about breast cancer:\n",
        "\n",
        "\n",
        "*   radius (mean of distances from center to points on the perimeter)\n",
        "*   texture (standard deviation of gray-scale values)\n",
        "\n",
        "* perimeter\n",
        "\n",
        "* area\n",
        "\n",
        "* smoothness (local variation in radius lengths)\n",
        "\n",
        "* compactness (perimeter^2 / area - 1.0)\n",
        "\n",
        "* concavity (severity of concave portions of the contour)\n",
        "\n",
        "* concave points (number of concave portions of the contour)\n",
        "\n",
        "* symmetry\n",
        "\n",
        "* fractal dimension (“coastline approximation” - 1)\n",
        "\n",
        "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utxOpPt7Gj5t"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "import warnings\n",
        "warnings.simplefilter(action=\"ignore\")"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecnfoEAeGktv"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "df = pd.DataFrame(np.c_[cancer['data'], cancer['target']],\n",
        "                            columns=np.append(cancer['feature_names'], ['target']))"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ovzkD1HJvz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "218785ec-cccb-470f-842c-595ef8f8ab2b"
      },
      "source": [
        "df"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0          17.99         10.38  ...                  0.11890     0.0\n",
              "1          20.57         17.77  ...                  0.08902     0.0\n",
              "2          19.69         21.25  ...                  0.08758     0.0\n",
              "3          11.42         20.38  ...                  0.17300     0.0\n",
              "4          20.29         14.34  ...                  0.07678     0.0\n",
              "..           ...           ...  ...                      ...     ...\n",
              "564        21.56         22.39  ...                  0.07115     0.0\n",
              "565        20.13         28.25  ...                  0.06637     0.0\n",
              "566        16.60         28.08  ...                  0.07820     0.0\n",
              "567        20.60         29.33  ...                  0.12400     0.0\n",
              "568         7.76         24.54  ...                  0.07039     1.0\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvXIhc6jHroe"
      },
      "source": [
        "## Data Inspection/Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVL1Pa-5Ht5u"
      },
      "source": [
        "#df.replace({'target': 1}, \"benign\", inplace=True)\n",
        "#df.replace({'target': 0}, \"malignant\", inplace=True)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH5K2kYQixWs",
        "outputId": "836e2c4b-c2d9-4e9c-c2ce-8797cc34a7ec"
      },
      "source": [
        "df['target'].value_counts()\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    357\n",
              "0.0    212\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfSfdKNCH-oN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e77e2385-1c6f-40c9-be3b-58b8a3563a25"
      },
      "source": [
        "# inspect the distribution\n",
        "\n",
        "sns.countplot(data = df, x='target')\n",
        "plt.title('Diagnosis');"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rty_ZwMA9sqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e92ca3-4100-48d7-b936-a02e72ff3fb8"
      },
      "source": [
        "#inspect the data and columns\n",
        "# count number of empty values in each column\n",
        "df.isnull().sum()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "target                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3d3YOyYjxv4",
        "outputId": "67a2ad94-0fff-4c7d-b225-afa8dc06a5fb"
      },
      "source": [
        "#look at the data types to see which columns need to be encoded\n",
        "df.dtypes\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                float64\n",
              "mean texture               float64\n",
              "mean perimeter             float64\n",
              "mean area                  float64\n",
              "mean smoothness            float64\n",
              "mean compactness           float64\n",
              "mean concavity             float64\n",
              "mean concave points        float64\n",
              "mean symmetry              float64\n",
              "mean fractal dimension     float64\n",
              "radius error               float64\n",
              "texture error              float64\n",
              "perimeter error            float64\n",
              "area error                 float64\n",
              "smoothness error           float64\n",
              "compactness error          float64\n",
              "concavity error            float64\n",
              "concave points error       float64\n",
              "symmetry error             float64\n",
              "fractal dimension error    float64\n",
              "worst radius               float64\n",
              "worst texture              float64\n",
              "worst perimeter            float64\n",
              "worst area                 float64\n",
              "worst smoothness           float64\n",
              "worst compactness          float64\n",
              "worst concavity            float64\n",
              "worst concave points       float64\n",
              "worst symmetry             float64\n",
              "worst fractal dimension    float64\n",
              "target                     float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egfds3xAULJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "983fe311-1b59-40a3-ee10-ce9203a9673e"
      },
      "source": [
        "#define X and y\n",
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1]\n",
        "y\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.0\n",
              "1      0.0\n",
              "2      0.0\n",
              "3      0.0\n",
              "4      0.0\n",
              "      ... \n",
              "564    0.0\n",
              "565    0.0\n",
              "566    0.0\n",
              "567    0.0\n",
              "568    1.0\n",
              "Name: target, Length: 569, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvNTnzqJCZcf"
      },
      "source": [
        "## 1) Split the Data into Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq_mpO7LCF1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59fa54c-9aec-417a-f19f-ec5c81bade69"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# use random state 42\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(398, 30)\n",
            "(171, 30)\n",
            "(171,)\n",
            "(398,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEu-XQIuLfE4"
      },
      "source": [
        "# feature scaling - standardscaler\n",
        "from sklearn import preprocessing\n",
        "scaler=preprocessing.StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n",
        "\n",
        "# scaled arrays\n",
        "\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnDZpY7dNGV4"
      },
      "source": [
        "## Create Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKopWmrJCnK_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bssc7Ctlld8h"
      },
      "source": [
        ""
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqhUBrRvCsS6"
      },
      "source": [
        "\n",
        "#adding the input and first hidden layer\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Dense(15,activation=\"relu\",input_dim=30))\n",
        "model.add(Dense(6,activation=\"relu\"))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trg8k2LwCyva"
      },
      "source": [
        "#compile the model\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAanQbf7l5Df"
      },
      "source": [
        "#show model summary\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjajWIPalsAp",
        "outputId": "c16a009b-3185-40e1-8f7c-facde68d522d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 15)                465       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 6)                 96        \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 568\n",
            "Trainable params: 568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-kHOxG_ImdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049a866d-2f7f-4bad-c1b5-52b6591a9998"
      },
      "source": [
        "# see if you can reproduce the parameters from input to hidden layer:\n",
        "\n",
        "print(X_train.shape[1] * 15 + 15)\n",
        "\n",
        "#(dimension of W_1)\n",
        "\n",
        "# first hidden to second hidden layer\n",
        "print(15 *6 +6)\n",
        "#(dimension of W_2))\n",
        "\n",
        "\n",
        "# second hidden to output layer\n",
        "print(6 * 1 +1)\n",
        "#(dimension of W_3 )"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "465\n",
            "96\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRVmifMsC1lS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84617ee9-dec9-4be2-a79b-91adcb3f586c"
      },
      "source": [
        "#fit the model\n",
        "model.fit(X_train,y_train,batch_size=32,epochs=100,validation_data=(X_test,y_test))\n",
        "\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 15ms/step - loss: 0.6693 - accuracy: 0.6332 - val_loss: 0.6060 - val_accuracy: 0.6491\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.6583 - val_loss: 0.5143 - val_accuracy: 0.7018\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7186 - val_loss: 0.4484 - val_accuracy: 0.7544\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7839 - val_loss: 0.3998 - val_accuracy: 0.8012\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8392 - val_loss: 0.3619 - val_accuracy: 0.8596\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8693 - val_loss: 0.3344 - val_accuracy: 0.9064\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8844 - val_loss: 0.3096 - val_accuracy: 0.9181\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.9146 - val_loss: 0.2858 - val_accuracy: 0.9474\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.9347 - val_loss: 0.2636 - val_accuracy: 0.9591\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2768 - accuracy: 0.9372 - val_loss: 0.2420 - val_accuracy: 0.9708\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.9598 - val_loss: 0.2214 - val_accuracy: 0.9766\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2348 - accuracy: 0.9698 - val_loss: 0.2022 - val_accuracy: 0.9708\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2161 - accuracy: 0.9698 - val_loss: 0.1844 - val_accuracy: 0.9649\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9724 - val_loss: 0.1685 - val_accuracy: 0.9649\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9724 - val_loss: 0.1540 - val_accuracy: 0.9649\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1682 - accuracy: 0.9749 - val_loss: 0.1410 - val_accuracy: 0.9708\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 0.9749 - val_loss: 0.1303 - val_accuracy: 0.9766\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1436 - accuracy: 0.9749 - val_loss: 0.1209 - val_accuracy: 0.9766\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9774 - val_loss: 0.1130 - val_accuracy: 0.9766\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1247 - accuracy: 0.9774 - val_loss: 0.1060 - val_accuracy: 0.9708\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.9799 - val_loss: 0.0998 - val_accuracy: 0.9766\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9799 - val_loss: 0.0946 - val_accuracy: 0.9825\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9799 - val_loss: 0.0900 - val_accuracy: 0.9825\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9799 - val_loss: 0.0862 - val_accuracy: 0.9883\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9799 - val_loss: 0.0823 - val_accuracy: 0.9883\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9799 - val_loss: 0.0796 - val_accuracy: 0.9883\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9799 - val_loss: 0.0769 - val_accuracy: 0.9883\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9799 - val_loss: 0.0743 - val_accuracy: 0.9883\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9799 - val_loss: 0.0728 - val_accuracy: 0.9825\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9799 - val_loss: 0.0707 - val_accuracy: 0.9825\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9799 - val_loss: 0.0689 - val_accuracy: 0.9825\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9799 - val_loss: 0.0681 - val_accuracy: 0.9825\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9799 - val_loss: 0.0666 - val_accuracy: 0.9825\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9799 - val_loss: 0.0656 - val_accuracy: 0.9825\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9799 - val_loss: 0.0646 - val_accuracy: 0.9825\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9799 - val_loss: 0.0632 - val_accuracy: 0.9825\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.9799 - val_loss: 0.0619 - val_accuracy: 0.9825\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9799 - val_loss: 0.0611 - val_accuracy: 0.9825\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9824 - val_loss: 0.0599 - val_accuracy: 0.9825\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9824 - val_loss: 0.0594 - val_accuracy: 0.9825\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9824 - val_loss: 0.0583 - val_accuracy: 0.9883\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9824 - val_loss: 0.0576 - val_accuracy: 0.9883\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9849 - val_loss: 0.0571 - val_accuracy: 0.9883\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9824 - val_loss: 0.0573 - val_accuracy: 0.9883\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9824 - val_loss: 0.0571 - val_accuracy: 0.9883\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 0.0562 - val_accuracy: 0.9883\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9874 - val_loss: 0.0558 - val_accuracy: 0.9883\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9849 - val_loss: 0.0557 - val_accuracy: 0.9883\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 0.0553 - val_accuracy: 0.9883\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9849 - val_loss: 0.0550 - val_accuracy: 0.9883\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9874 - val_loss: 0.0546 - val_accuracy: 0.9883\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9899 - val_loss: 0.0539 - val_accuracy: 0.9883\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9899 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9925 - val_loss: 0.0541 - val_accuracy: 0.9883\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9925 - val_loss: 0.0539 - val_accuracy: 0.9883\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9925 - val_loss: 0.0534 - val_accuracy: 0.9883\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9899 - val_loss: 0.0532 - val_accuracy: 0.9883\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9925 - val_loss: 0.0531 - val_accuracy: 0.9883\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9925 - val_loss: 0.0537 - val_accuracy: 0.9883\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9925 - val_loss: 0.0536 - val_accuracy: 0.9883\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9925 - val_loss: 0.0534 - val_accuracy: 0.9883\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9925 - val_loss: 0.0532 - val_accuracy: 0.9883\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9925 - val_loss: 0.0534 - val_accuracy: 0.9883\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9925 - val_loss: 0.0531 - val_accuracy: 0.9883\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9925 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9925 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9925 - val_loss: 0.0534 - val_accuracy: 0.9883\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9925 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9925 - val_loss: 0.0543 - val_accuracy: 0.9883\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9925 - val_loss: 0.0539 - val_accuracy: 0.9883\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9925 - val_loss: 0.0539 - val_accuracy: 0.9883\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9925 - val_loss: 0.0537 - val_accuracy: 0.9883\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9925 - val_loss: 0.0535 - val_accuracy: 0.9883\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9925 - val_loss: 0.0537 - val_accuracy: 0.9883\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9925 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9925 - val_loss: 0.0539 - val_accuracy: 0.9883\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0260 - accuracy: 0.9925 - val_loss: 0.0539 - val_accuracy: 0.9883\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 0.0561 - val_accuracy: 0.9883\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.0562 - val_accuracy: 0.9883\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0560 - val_accuracy: 0.9883\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.0566 - val_accuracy: 0.9883\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0572 - val_accuracy: 0.9825\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9925 - val_loss: 0.0576 - val_accuracy: 0.9825\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0573 - val_accuracy: 0.9825\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0575 - val_accuracy: 0.9825\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0597 - val_accuracy: 0.9825\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.0615 - val_accuracy: 0.9825\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9925 - val_loss: 0.0617 - val_accuracy: 0.9825\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9950 - val_loss: 0.0614 - val_accuracy: 0.9825\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.0629 - val_accuracy: 0.9825\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9925 - val_loss: 0.0632 - val_accuracy: 0.9825\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.0628 - val_accuracy: 0.9825\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9925 - val_loss: 0.0628 - val_accuracy: 0.9825\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.0640 - val_accuracy: 0.9825\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0647 - val_accuracy: 0.9825\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9925 - val_loss: 0.0646 - val_accuracy: 0.9825\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.0655 - val_accuracy: 0.9825\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.0657 - val_accuracy: 0.9825\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.0661 - val_accuracy: 0.9825\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0899e9ce50>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qBTMOIcFLGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8abfc0-60ff-4963-a272-646daccf00b6"
      },
      "source": [
        "#evaluate the model and save it into the variable score\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "score"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06605783104896545, 0.9824561476707458]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9aygjgtJUiv"
      },
      "source": [
        "The metrics that *evaluate()* gives us depend on the input argument *metrics* that we used when setting up our NN. Keras knows several other metrics (see [Keras doc. for details](https://keras.io/metrics/)) but not all known metrics are supported for training the NN. Between, you can also extend the set of metrics with customer metrics (see this [example](https://machinelearningmastery.com/custom-metrics-deep-learning-keras-python/) if interested.).\n",
        "\n",
        "We also have access to model performance results via the result of *model.fit()*, that is our variable *story*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzrrd6XLWvXg"
      },
      "source": [
        "# Now install the tensorflow addons and define the following metrics. You have AUC,Precision and Recall in Keras Metrics but F1 you will need to get it from tensorflow addons\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPRMM0usWor3",
        "outputId": "6d57198f-2d0f-48e2-eed5-7924dd502195"
      },
      "source": [
        "!pip install tensorflow-addons\n",
        "\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4zWF58rWmcG"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf \n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "metrics = [ \n",
        "    #keras.metrics.Precision(),\n",
        "    #keras.metrics.Recall(),\n",
        "    keras.metrics.AUC(),\n",
        "    #tfa.metrics.F1Score(\n",
        "    #    name=\"f1_micro\",\n",
        "    #    average=\"micro\",\n",
        "    #    num_classes=1,\n",
        "    #    threshold=0.5,\n",
        "    #),\n",
        "    #tfa.metrics.F1Score(\n",
        "    #    name=\"f1_weighted\",\n",
        "    #    average=\"weighted\",\n",
        "    #    num_classes=1,\n",
        "    #    threshold=0.5,\n",
        "    #),\n",
        "]"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeYiEkLjW2hE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccc57bf-9dcf-4f7d-a6c6-9f2d2bdc18b0"
      },
      "source": [
        "# rerun the mmodel with the above defined metrics in your complie call\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy', keras.metrics.AUC()])\n",
        "\n",
        "story = model.fit(X_train,y_train,batch_size=32,epochs=100,validation_data=(X_test,y_test))\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 26ms/step - loss: 0.6746 - accuracy: 0.5176 - auc_4: 0.6663 - val_loss: 0.5976 - val_accuracy: 0.6725 - val_auc_4: 0.7925\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7161 - auc_4: 0.8505 - val_loss: 0.4985 - val_accuracy: 0.8480 - val_auc_4: 0.9347\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.8593 - auc_4: 0.9384 - val_loss: 0.4258 - val_accuracy: 0.9298 - val_auc_4: 0.9706\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.9171 - auc_4: 0.9704 - val_loss: 0.3531 - val_accuracy: 0.9357 - val_auc_4: 0.9787\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3237 - accuracy: 0.9271 - auc_4: 0.9765 - val_loss: 0.2895 - val_accuracy: 0.9474 - val_auc_4: 0.9832\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.9372 - auc_4: 0.9789 - val_loss: 0.2417 - val_accuracy: 0.9474 - val_auc_4: 0.9861\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2298 - accuracy: 0.9447 - auc_4: 0.9822 - val_loss: 0.2058 - val_accuracy: 0.9415 - val_auc_4: 0.9892\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2016 - accuracy: 0.9447 - auc_4: 0.9840 - val_loss: 0.1815 - val_accuracy: 0.9415 - val_auc_4: 0.9902\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1813 - accuracy: 0.9523 - auc_4: 0.9854 - val_loss: 0.1625 - val_accuracy: 0.9415 - val_auc_4: 0.9915\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1650 - accuracy: 0.9523 - auc_4: 0.9874 - val_loss: 0.1475 - val_accuracy: 0.9415 - val_auc_4: 0.9927\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.9523 - auc_4: 0.9884 - val_loss: 0.1352 - val_accuracy: 0.9474 - val_auc_4: 0.9936\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1413 - accuracy: 0.9523 - auc_4: 0.9892 - val_loss: 0.1249 - val_accuracy: 0.9532 - val_auc_4: 0.9940\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1320 - accuracy: 0.9523 - auc_4: 0.9900 - val_loss: 0.1165 - val_accuracy: 0.9532 - val_auc_4: 0.9949\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.9573 - auc_4: 0.9906 - val_loss: 0.1088 - val_accuracy: 0.9532 - val_auc_4: 0.9953\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.9573 - auc_4: 0.9915 - val_loss: 0.1025 - val_accuracy: 0.9591 - val_auc_4: 0.9954\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1105 - accuracy: 0.9598 - auc_4: 0.9920 - val_loss: 0.0971 - val_accuracy: 0.9649 - val_auc_4: 0.9959\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9623 - auc_4: 0.9923 - val_loss: 0.0929 - val_accuracy: 0.9591 - val_auc_4: 0.9957\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1005 - accuracy: 0.9673 - auc_4: 0.9929 - val_loss: 0.0892 - val_accuracy: 0.9591 - val_auc_4: 0.9959\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9673 - auc_4: 0.9935 - val_loss: 0.0865 - val_accuracy: 0.9591 - val_auc_4: 0.9963\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0922 - accuracy: 0.9749 - auc_4: 0.9940 - val_loss: 0.0833 - val_accuracy: 0.9649 - val_auc_4: 0.9964\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9749 - auc_4: 0.9945 - val_loss: 0.0799 - val_accuracy: 0.9649 - val_auc_4: 0.9968\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9749 - auc_4: 0.9947 - val_loss: 0.0773 - val_accuracy: 0.9649 - val_auc_4: 0.9971\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9749 - auc_4: 0.9948 - val_loss: 0.0750 - val_accuracy: 0.9649 - val_auc_4: 0.9973\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9749 - auc_4: 0.9952 - val_loss: 0.0734 - val_accuracy: 0.9708 - val_auc_4: 0.9973\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9774 - auc_4: 0.9956 - val_loss: 0.0720 - val_accuracy: 0.9708 - val_auc_4: 0.9972\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9774 - auc_4: 0.9959 - val_loss: 0.0706 - val_accuracy: 0.9708 - val_auc_4: 0.9972\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9774 - auc_4: 0.9958 - val_loss: 0.0694 - val_accuracy: 0.9708 - val_auc_4: 0.9975\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9774 - auc_4: 0.9960 - val_loss: 0.0682 - val_accuracy: 0.9708 - val_auc_4: 0.9974\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9774 - auc_4: 0.9962 - val_loss: 0.0669 - val_accuracy: 0.9708 - val_auc_4: 0.9972\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9799 - auc_4: 0.9964 - val_loss: 0.0659 - val_accuracy: 0.9708 - val_auc_4: 0.9978\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9799 - auc_4: 0.9965 - val_loss: 0.0657 - val_accuracy: 0.9708 - val_auc_4: 0.9980\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9824 - auc_4: 0.9967 - val_loss: 0.0651 - val_accuracy: 0.9708 - val_auc_4: 0.9978\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9824 - auc_4: 0.9969 - val_loss: 0.0646 - val_accuracy: 0.9708 - val_auc_4: 0.9977\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9824 - auc_4: 0.9969 - val_loss: 0.0640 - val_accuracy: 0.9708 - val_auc_4: 0.9976\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9824 - auc_4: 0.9971 - val_loss: 0.0637 - val_accuracy: 0.9708 - val_auc_4: 0.9979\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9824 - auc_4: 0.9971 - val_loss: 0.0636 - val_accuracy: 0.9708 - val_auc_4: 0.9976\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0569 - accuracy: 0.9849 - auc_4: 0.9972 - val_loss: 0.0628 - val_accuracy: 0.9708 - val_auc_4: 0.9978\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.9849 - auc_4: 0.9973 - val_loss: 0.0623 - val_accuracy: 0.9766 - val_auc_4: 0.9978\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9849 - auc_4: 0.9974 - val_loss: 0.0623 - val_accuracy: 0.9766 - val_auc_4: 0.9979\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9849 - auc_4: 0.9975 - val_loss: 0.0626 - val_accuracy: 0.9708 - val_auc_4: 0.9978\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9849 - auc_4: 0.9976 - val_loss: 0.0620 - val_accuracy: 0.9708 - val_auc_4: 0.9979\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9849 - auc_4: 0.9976 - val_loss: 0.0619 - val_accuracy: 0.9766 - val_auc_4: 0.9979\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9849 - auc_4: 0.9980 - val_loss: 0.0615 - val_accuracy: 0.9766 - val_auc_4: 0.9978\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9849 - auc_4: 0.9980 - val_loss: 0.0611 - val_accuracy: 0.9766 - val_auc_4: 0.9977\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9849 - auc_4: 0.9981 - val_loss: 0.0607 - val_accuracy: 0.9766 - val_auc_4: 0.9977\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0471 - accuracy: 0.9849 - auc_4: 0.9982 - val_loss: 0.0603 - val_accuracy: 0.9766 - val_auc_4: 0.9976\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9849 - auc_4: 0.9984 - val_loss: 0.0598 - val_accuracy: 0.9766 - val_auc_4: 0.9977\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9849 - auc_4: 0.9984 - val_loss: 0.0599 - val_accuracy: 0.9766 - val_auc_4: 0.9976\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9874 - auc_4: 0.9984 - val_loss: 0.0594 - val_accuracy: 0.9766 - val_auc_4: 0.9976\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9874 - auc_4: 0.9985 - val_loss: 0.0589 - val_accuracy: 0.9766 - val_auc_4: 0.9976\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9874 - auc_4: 0.9986 - val_loss: 0.0575 - val_accuracy: 0.9766 - val_auc_4: 0.9976\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9874 - auc_4: 0.9986 - val_loss: 0.0574 - val_accuracy: 0.9766 - val_auc_4: 0.9976\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9874 - auc_4: 0.9986 - val_loss: 0.0570 - val_accuracy: 0.9766 - val_auc_4: 0.9976\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9874 - auc_4: 0.9987 - val_loss: 0.0575 - val_accuracy: 0.9766 - val_auc_4: 0.9978\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9899 - auc_4: 0.9987 - val_loss: 0.0573 - val_accuracy: 0.9766 - val_auc_4: 0.9977\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9925 - auc_4: 0.9988 - val_loss: 0.0570 - val_accuracy: 0.9766 - val_auc_4: 0.9979\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9925 - auc_4: 0.9988 - val_loss: 0.0568 - val_accuracy: 0.9766 - val_auc_4: 0.9978\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9925 - auc_4: 0.9988 - val_loss: 0.0572 - val_accuracy: 0.9766 - val_auc_4: 0.9979\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9925 - auc_4: 0.9990 - val_loss: 0.0569 - val_accuracy: 0.9766 - val_auc_4: 0.9979\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9925 - auc_4: 0.9990 - val_loss: 0.0561 - val_accuracy: 0.9766 - val_auc_4: 0.9979\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9925 - auc_4: 0.9991 - val_loss: 0.0560 - val_accuracy: 0.9825 - val_auc_4: 0.9979\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9925 - auc_4: 0.9991 - val_loss: 0.0567 - val_accuracy: 0.9766 - val_auc_4: 0.9979\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9925 - auc_4: 0.9991 - val_loss: 0.0568 - val_accuracy: 0.9825 - val_auc_4: 0.9978\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9925 - auc_4: 0.9992 - val_loss: 0.0575 - val_accuracy: 0.9825 - val_auc_4: 0.9977\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9925 - auc_4: 0.9992 - val_loss: 0.0572 - val_accuracy: 0.9825 - val_auc_4: 0.9978\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9925 - auc_4: 0.9993 - val_loss: 0.0580 - val_accuracy: 0.9825 - val_auc_4: 0.9978\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9925 - auc_4: 0.9993 - val_loss: 0.0584 - val_accuracy: 0.9825 - val_auc_4: 0.9978\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9925 - auc_4: 0.9994 - val_loss: 0.0591 - val_accuracy: 0.9825 - val_auc_4: 0.9978\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9925 - auc_4: 0.9994 - val_loss: 0.0597 - val_accuracy: 0.9825 - val_auc_4: 0.9977\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0294 - accuracy: 0.9925 - auc_4: 0.9994 - val_loss: 0.0590 - val_accuracy: 0.9825 - val_auc_4: 0.9977\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9925 - auc_4: 0.9995 - val_loss: 0.0607 - val_accuracy: 0.9766 - val_auc_4: 0.9977\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9925 - auc_4: 0.9995 - val_loss: 0.0598 - val_accuracy: 0.9825 - val_auc_4: 0.9976\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9925 - auc_4: 0.9995 - val_loss: 0.0600 - val_accuracy: 0.9825 - val_auc_4: 0.9976\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9925 - auc_4: 0.9995 - val_loss: 0.0598 - val_accuracy: 0.9766 - val_auc_4: 0.9977\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9925 - auc_4: 0.9996 - val_loss: 0.0593 - val_accuracy: 0.9766 - val_auc_4: 0.9976\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9925 - auc_4: 0.9996 - val_loss: 0.0589 - val_accuracy: 0.9766 - val_auc_4: 0.9976\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9925 - auc_4: 0.9996 - val_loss: 0.0604 - val_accuracy: 0.9766 - val_auc_4: 0.9976\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9925 - auc_4: 0.9996 - val_loss: 0.0613 - val_accuracy: 0.9766 - val_auc_4: 0.9974\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9925 - auc_4: 0.9997 - val_loss: 0.0613 - val_accuracy: 0.9766 - val_auc_4: 0.9975\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9925 - auc_4: 0.9997 - val_loss: 0.0616 - val_accuracy: 0.9766 - val_auc_4: 0.9971\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9925 - auc_4: 0.9997 - val_loss: 0.0616 - val_accuracy: 0.9766 - val_auc_4: 0.9971\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9925 - auc_4: 0.9997 - val_loss: 0.0615 - val_accuracy: 0.9766 - val_auc_4: 0.9971\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9925 - auc_4: 0.9997 - val_loss: 0.0618 - val_accuracy: 0.9766 - val_auc_4: 0.9971\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 0.9950 - auc_4: 0.9997 - val_loss: 0.0624 - val_accuracy: 0.9766 - val_auc_4: 0.9969\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9925 - auc_4: 0.9998 - val_loss: 0.0635 - val_accuracy: 0.9766 - val_auc_4: 0.9968\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0222 - accuracy: 0.9950 - auc_4: 0.9998 - val_loss: 0.0634 - val_accuracy: 0.9766 - val_auc_4: 0.9966\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 0.9950 - auc_4: 0.9998 - val_loss: 0.0645 - val_accuracy: 0.9766 - val_auc_4: 0.9968\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0213 - accuracy: 0.9950 - auc_4: 0.9998 - val_loss: 0.0637 - val_accuracy: 0.9766 - val_auc_4: 0.9968\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0210 - accuracy: 0.9950 - auc_4: 0.9998 - val_loss: 0.0665 - val_accuracy: 0.9766 - val_auc_4: 0.9965\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9950 - auc_4: 0.9998 - val_loss: 0.0668 - val_accuracy: 0.9766 - val_auc_4: 0.9967\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9950 - auc_4: 0.9998 - val_loss: 0.0662 - val_accuracy: 0.9766 - val_auc_4: 0.9964\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9950 - auc_4: 0.9998 - val_loss: 0.0661 - val_accuracy: 0.9766 - val_auc_4: 0.9965\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9950 - auc_4: 0.9999 - val_loss: 0.0669 - val_accuracy: 0.9766 - val_auc_4: 0.9965\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9950 - auc_4: 0.9999 - val_loss: 0.0664 - val_accuracy: 0.9766 - val_auc_4: 0.9965\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9950 - auc_4: 0.9999 - val_loss: 0.0669 - val_accuracy: 0.9766 - val_auc_4: 0.9965\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9950 - auc_4: 0.9999 - val_loss: 0.0682 - val_accuracy: 0.9766 - val_auc_4: 0.9965\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 0.9950 - auc_4: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9766 - val_auc_4: 0.9965\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9950 - auc_4: 0.9999 - val_loss: 0.0692 - val_accuracy: 0.9766 - val_auc_4: 0.9966\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9950 - auc_4: 0.9999 - val_loss: 0.0686 - val_accuracy: 0.9766 - val_auc_4: 0.9963\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9950 - auc_4: 0.9999 - val_loss: 0.0688 - val_accuracy: 0.9766 - val_auc_4: 0.9963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_DLHy3BFemk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "487423d1-d704-44c9-ad36-e2f6ab2d6875"
      },
      "source": [
        "# print Test Loss and Accuracy and plot the history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_history(story):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18.5, 10.5)\n",
        "    ax1.plot(story.history['accuracy'])\n",
        "    ax1.plot(story.history['val_accuracy'])\n",
        "    ax1.set(xlabel='epoch', ylabel='accuracy')\n",
        "    ax1.legend(['train_accuracy', 'val_accuracy'], loc='best')\n",
        "    ax1.set_title('Accuracy evolution during NN training')\n",
        "    \n",
        "    ax2.plot(story.history['loss'])\n",
        "    ax2.plot(story.history['val_loss'])\n",
        "    ax2.set(xlabel='epoch', ylabel='loss')\n",
        "    ax2.legend(['train_loss', 'val_loss'], loc='best')\n",
        "    ax2.set_title('Loss evolution during NN training')\n",
        "    plt.show()\n",
        "\n",
        "show_history(story)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1332x756 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ4AwjONFbRV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JOpM-jmuO-W"
      },
      "source": [
        "Typically validation loss should be similar to but slightly higher than training loss. As long as validation loss is lower than or even equal to training loss one should keep doing more training. If training loss is reducing without increase in validation loss then again keep doing more training. If validation loss starts increasing then it is time to stop. Some over-fitting is nearly always a good thing. All that matters in the end is: is the validation loss as low as you can get it!\n",
        "\n",
        "If overall accuracy still not acceptable then review mistakes model is making and think of what can one change: More data? More / different data augmentations? Different architecture?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXFMSTVhJh02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211f1bc2-445b-40d9-bf6c-881bb3499e7c"
      },
      "source": [
        "# Compute predictions of X_test\n",
        "yhat = model.predict(X_test)\n",
        "yhat"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.58005786e-01],\n",
              "       [2.42273011e-08],\n",
              "       [8.80501102e-05],\n",
              "       [9.99769688e-01],\n",
              "       [9.99946594e-01],\n",
              "       [4.60487175e-15],\n",
              "       [2.69571637e-13],\n",
              "       [5.78492880e-04],\n",
              "       [2.61843026e-01],\n",
              "       [9.99860048e-01],\n",
              "       [6.90617800e-01],\n",
              "       [6.56604767e-04],\n",
              "       [9.96563256e-01],\n",
              "       [1.86347961e-03],\n",
              "       [9.99834180e-01],\n",
              "       [1.46089201e-06],\n",
              "       [9.99746561e-01],\n",
              "       [9.99976277e-01],\n",
              "       [9.99998927e-01],\n",
              "       [2.39539877e-09],\n",
              "       [9.80181575e-01],\n",
              "       [9.95892048e-01],\n",
              "       [3.33773590e-13],\n",
              "       [9.99690771e-01],\n",
              "       [9.99325037e-01],\n",
              "       [9.99775529e-01],\n",
              "       [9.99849558e-01],\n",
              "       [9.99063849e-01],\n",
              "       [9.97559667e-01],\n",
              "       [1.89319316e-09],\n",
              "       [9.99274194e-01],\n",
              "       [9.99948144e-01],\n",
              "       [9.98904347e-01],\n",
              "       [9.98590827e-01],\n",
              "       [9.99903619e-01],\n",
              "       [9.98852015e-01],\n",
              "       [6.90257549e-03],\n",
              "       [9.98767972e-01],\n",
              "       [3.65681331e-07],\n",
              "       [9.67260718e-01],\n",
              "       [9.99818742e-01],\n",
              "       [1.28112697e-05],\n",
              "       [9.99296665e-01],\n",
              "       [9.99230266e-01],\n",
              "       [9.65589881e-01],\n",
              "       [9.60521698e-01],\n",
              "       [9.99981761e-01],\n",
              "       [9.98188317e-01],\n",
              "       [9.69446898e-01],\n",
              "       [9.99353528e-01],\n",
              "       [7.77927653e-07],\n",
              "       [3.14727355e-10],\n",
              "       [8.73848319e-01],\n",
              "       [9.27173793e-01],\n",
              "       [9.99993920e-01],\n",
              "       [9.98418272e-01],\n",
              "       [9.99974370e-01],\n",
              "       [1.36807349e-16],\n",
              "       [1.35636330e-03],\n",
              "       [9.99955773e-01],\n",
              "       [9.96524155e-01],\n",
              "       [8.32120414e-11],\n",
              "       [2.69508916e-13],\n",
              "       [9.80694234e-01],\n",
              "       [9.99150515e-01],\n",
              "       [9.78035212e-01],\n",
              "       [1.95732959e-08],\n",
              "       [6.91983526e-13],\n",
              "       [9.99521494e-01],\n",
              "       [9.96662498e-01],\n",
              "       [4.35157381e-05],\n",
              "       [4.23375104e-06],\n",
              "       [9.99251962e-01],\n",
              "       [2.63382353e-05],\n",
              "       [9.99938726e-01],\n",
              "       [9.99046206e-01],\n",
              "       [9.76833880e-01],\n",
              "       [3.75349790e-01],\n",
              "       [9.99937892e-01],\n",
              "       [9.98136103e-01],\n",
              "       [4.28348780e-04],\n",
              "       [9.99958158e-01],\n",
              "       [2.42894620e-01],\n",
              "       [4.28012790e-12],\n",
              "       [2.73823738e-04],\n",
              "       [4.74431914e-07],\n",
              "       [3.15799070e-07],\n",
              "       [1.74096895e-05],\n",
              "       [9.99982595e-01],\n",
              "       [9.98804808e-01],\n",
              "       [9.96063709e-01],\n",
              "       [2.33360946e-01],\n",
              "       [9.87329483e-01],\n",
              "       [9.94661570e-01],\n",
              "       [9.99828815e-01],\n",
              "       [9.99937296e-01],\n",
              "       [1.16227454e-08],\n",
              "       [1.43046153e-09],\n",
              "       [9.99975920e-01],\n",
              "       [6.07192942e-06],\n",
              "       [3.72990144e-05],\n",
              "       [9.99998808e-01],\n",
              "       [4.61270089e-09],\n",
              "       [1.84177884e-06],\n",
              "       [9.89630997e-01],\n",
              "       [9.63201165e-01],\n",
              "       [9.98630881e-01],\n",
              "       [2.69276898e-15],\n",
              "       [9.91009712e-01],\n",
              "       [9.84467506e-01],\n",
              "       [1.33688172e-05],\n",
              "       [9.99198556e-01],\n",
              "       [9.84035850e-01],\n",
              "       [6.32728318e-16],\n",
              "       [1.39405072e-01],\n",
              "       [1.17612910e-13],\n",
              "       [9.99998212e-01],\n",
              "       [8.65849137e-01],\n",
              "       [9.99955177e-01],\n",
              "       [2.20155059e-07],\n",
              "       [9.99996305e-01],\n",
              "       [9.99713659e-01],\n",
              "       [9.96820569e-01],\n",
              "       [1.53018647e-07],\n",
              "       [9.83212590e-01],\n",
              "       [6.36822192e-11],\n",
              "       [1.97007921e-06],\n",
              "       [9.99177158e-01],\n",
              "       [9.99549270e-01],\n",
              "       [1.54136726e-09],\n",
              "       [8.34516429e-13],\n",
              "       [7.33745198e-09],\n",
              "       [9.97932792e-01],\n",
              "       [9.98787045e-01],\n",
              "       [9.99160886e-01],\n",
              "       [6.52801100e-06],\n",
              "       [7.91080832e-01],\n",
              "       [9.98006046e-01],\n",
              "       [6.94866180e-01],\n",
              "       [7.73841384e-06],\n",
              "       [9.98188734e-01],\n",
              "       [4.34407989e-13],\n",
              "       [9.99989271e-01],\n",
              "       [9.99993682e-01],\n",
              "       [1.03468454e-04],\n",
              "       [9.99796271e-01],\n",
              "       [3.85278653e-08],\n",
              "       [3.07241055e-09],\n",
              "       [4.30807769e-02],\n",
              "       [9.99732137e-01],\n",
              "       [3.47897410e-03],\n",
              "       [9.99879241e-01],\n",
              "       [9.99993980e-01],\n",
              "       [9.88107920e-01],\n",
              "       [9.98661280e-01],\n",
              "       [5.26440034e-18],\n",
              "       [1.48178083e-06],\n",
              "       [9.99943852e-01],\n",
              "       [9.98543024e-01],\n",
              "       [9.99972522e-01],\n",
              "       [9.99992788e-01],\n",
              "       [9.99943256e-01],\n",
              "       [9.99836445e-01],\n",
              "       [9.98437524e-01],\n",
              "       [4.85669374e-02],\n",
              "       [9.99852598e-01],\n",
              "       [9.99546766e-01],\n",
              "       [6.38934612e-01],\n",
              "       [9.99997377e-01],\n",
              "       [2.12669373e-04],\n",
              "       [9.99201655e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32rVq2dmK76Q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YLpHjipKbZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633e93df-7d69-429e-edc6-8c55ba5f6105"
      },
      "source": [
        "# Finding the most probable class\n",
        "yhat_c = (yhat > 0.5)\n",
        "print(yhat_c)\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttv8CTL9J2u9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad4e6a0-6f22-49a2-e1d2-24c95b83bafc"
      },
      "source": [
        "# print the confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "cm = confusion_matrix(y_test,yhat_c)\n",
        "score = accuracy_score(y_test,yhat_c)\n",
        "print(cm)\n",
        "print('score is:',score)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 62   1]\n",
            " [  3 105]]\n",
            "score is: 0.9766081871345029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y_9kW-HNogg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd34520-af75-4f56-c220-bb13bf88334d"
      },
      "source": [
        " #print calssification report\n",
        " from sklearn.metrics import classification_report\n",
        "\n",
        " print(classification_report(y_test, yhat_c))\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98        63\n",
            "           1       0.98      0.99      0.99       108\n",
            "\n",
            "   micro avg       0.98      0.98      0.98       171\n",
            "   macro avg       0.98      0.98      0.98       171\n",
            "weighted avg       0.98      0.98      0.98       171\n",
            " samples avg       0.98      0.98      0.98       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isYWxE5ibO7a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l0Wu5DMbQDI"
      },
      "source": [
        "\n",
        "# OPTION 2\n",
        "Lets implement the same model with softmax output activation and 2 nodes. REMEMBER, the binary classification case is a special case of the multiclass classification case with 2 classes. so the softmax function with only 2 classes will give the sigmoid function. \n",
        "MEaning, when you have a binary classification problem, have 2 options\n",
        "1.  output activation sigmoid, 1 node and binary_crossentropy loss\n",
        "2. output activation softmax, 2 nodes and categorical_crossentropy loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8emx5bGaHoc",
        "outputId": "35db0392-4e88-4e22-8893-ee360a3fcdef"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "# Prepare the target variable\n",
        "\n",
        "# if you use categorical crossentropy loss, you have to reshape the target variable to the dimension of the classes,\n",
        "# ie. OneHot encode the Target\n",
        "# Note: you can leave the target as normal integers, but then you have to use 'sparse_categorical_crossentropy' loss\n",
        "dummy_y = np_utils.to_categorical(y)\n",
        "dummy_y"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pem2hXWcafVj",
        "outputId": "231807a3-f4da-4400-fdad-cb8f4018fa19"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# use random state 42\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(398, 30)\n",
            "(171, 30)\n",
            "(171,)\n",
            "(398,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PI5IWC4apTM"
      },
      "source": [
        "# feature scaling - standardscaler\n",
        "from sklearn import preprocessing\n",
        "scaler=preprocessing.StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n",
        "\n",
        "# scaled arrays"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8dJ82XAAQ9f"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(15,activation=\"relu\",input_dim=30))\n",
        "model.add(Dense(6,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"softmax\"))"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcKPmuaTX06e"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg_AkIw9YMAm",
        "outputId": "28cd23ae-6cfa-477d-8bbb-08b66b6169b0"
      },
      "source": [
        "#fit the model\n",
        "model.fit(X_train,y_train,batch_size=32,epochs=100,validation_data=(X_test,y_test))\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 15ms/step - loss: 0.6824 - accuracy: 0.5854 - val_loss: 0.5961 - val_accuracy: 0.7193\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7940 - val_loss: 0.4558 - val_accuracy: 0.8304\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8744 - val_loss: 0.3688 - val_accuracy: 0.8947\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8970 - val_loss: 0.3061 - val_accuracy: 0.9064\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2882 - accuracy: 0.9070 - val_loss: 0.2581 - val_accuracy: 0.9123\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2497 - accuracy: 0.9221 - val_loss: 0.2210 - val_accuracy: 0.9357\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2198 - accuracy: 0.9372 - val_loss: 0.1915 - val_accuracy: 0.9474\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1954 - accuracy: 0.9397 - val_loss: 0.1688 - val_accuracy: 0.9532\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1767 - accuracy: 0.9447 - val_loss: 0.1497 - val_accuracy: 0.9532\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.9548 - val_loss: 0.1339 - val_accuracy: 0.9532\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1472 - accuracy: 0.9573 - val_loss: 0.1217 - val_accuracy: 0.9649\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9523 - val_loss: 0.1114 - val_accuracy: 0.9708\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9523 - val_loss: 0.1027 - val_accuracy: 0.9766\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9573 - val_loss: 0.0948 - val_accuracy: 0.9766\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.9623 - val_loss: 0.0892 - val_accuracy: 0.9766\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.9673 - val_loss: 0.0837 - val_accuracy: 0.9766\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0986 - accuracy: 0.9673 - val_loss: 0.0789 - val_accuracy: 0.9766\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9698 - val_loss: 0.0767 - val_accuracy: 0.9708\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9698 - val_loss: 0.0739 - val_accuracy: 0.9708\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9698 - val_loss: 0.0709 - val_accuracy: 0.9708\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9724 - val_loss: 0.0679 - val_accuracy: 0.9708\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9774 - val_loss: 0.0657 - val_accuracy: 0.9708\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9749 - val_loss: 0.0632 - val_accuracy: 0.9825\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9749 - val_loss: 0.0612 - val_accuracy: 0.9825\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9774 - val_loss: 0.0601 - val_accuracy: 0.9825\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9774 - val_loss: 0.0596 - val_accuracy: 0.9825\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9799 - val_loss: 0.0583 - val_accuracy: 0.9825\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9824 - val_loss: 0.0575 - val_accuracy: 0.9825\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9824 - val_loss: 0.0576 - val_accuracy: 0.9766\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9799 - val_loss: 0.0568 - val_accuracy: 0.9708\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9824 - val_loss: 0.0557 - val_accuracy: 0.9708\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9824 - val_loss: 0.0544 - val_accuracy: 0.9825\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.9824 - val_loss: 0.0535 - val_accuracy: 0.9766\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9849 - val_loss: 0.0531 - val_accuracy: 0.9825\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9849 - val_loss: 0.0522 - val_accuracy: 0.9825\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9874 - val_loss: 0.0537 - val_accuracy: 0.9766\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9849 - val_loss: 0.0534 - val_accuracy: 0.9766\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9849 - val_loss: 0.0526 - val_accuracy: 0.9766\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 0.0528 - val_accuracy: 0.9766\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9874 - val_loss: 0.0516 - val_accuracy: 0.9766\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9874 - val_loss: 0.0520 - val_accuracy: 0.9766\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9874 - val_loss: 0.0514 - val_accuracy: 0.9766\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 0.9899 - val_loss: 0.0507 - val_accuracy: 0.9825\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9899 - val_loss: 0.0505 - val_accuracy: 0.9825\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9899 - val_loss: 0.0495 - val_accuracy: 0.9825\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9899 - val_loss: 0.0501 - val_accuracy: 0.9825\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9899 - val_loss: 0.0507 - val_accuracy: 0.9766\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9899 - val_loss: 0.0504 - val_accuracy: 0.9766\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9899 - val_loss: 0.0506 - val_accuracy: 0.9766\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9899 - val_loss: 0.0500 - val_accuracy: 0.9825\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9899 - val_loss: 0.0505 - val_accuracy: 0.9766\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9899 - val_loss: 0.0497 - val_accuracy: 0.9825\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9899 - val_loss: 0.0505 - val_accuracy: 0.9766\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0336 - accuracy: 0.9899 - val_loss: 0.0511 - val_accuracy: 0.9766\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0329 - accuracy: 0.9899 - val_loss: 0.0515 - val_accuracy: 0.9766\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.0514 - val_accuracy: 0.9766\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9899 - val_loss: 0.0520 - val_accuracy: 0.9766\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.0528 - val_accuracy: 0.9766\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9925 - val_loss: 0.0524 - val_accuracy: 0.9766\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 0.9899 - val_loss: 0.0526 - val_accuracy: 0.9825\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9899 - val_loss: 0.0542 - val_accuracy: 0.9766\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9925 - val_loss: 0.0539 - val_accuracy: 0.9766\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9925 - val_loss: 0.0543 - val_accuracy: 0.9766\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 0.0551 - val_accuracy: 0.9766\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9925 - val_loss: 0.0557 - val_accuracy: 0.9766\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.0567 - val_accuracy: 0.9766\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.0554 - val_accuracy: 0.9766\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 0.0554 - val_accuracy: 0.9766\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.0575 - val_accuracy: 0.9766\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.0574 - val_accuracy: 0.9708\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9950 - val_loss: 0.0592 - val_accuracy: 0.9766\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9950 - val_loss: 0.0588 - val_accuracy: 0.9766\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9950 - val_loss: 0.0591 - val_accuracy: 0.9766\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9950 - val_loss: 0.0588 - val_accuracy: 0.9766\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9950 - val_loss: 0.0619 - val_accuracy: 0.9766\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9950 - val_loss: 0.0655 - val_accuracy: 0.9766\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.0663 - val_accuracy: 0.9766\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.0647 - val_accuracy: 0.9766\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.0648 - val_accuracy: 0.9766\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.0654 - val_accuracy: 0.9766\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.0646 - val_accuracy: 0.9766\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.0654 - val_accuracy: 0.9766\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.0647 - val_accuracy: 0.9766\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.0665 - val_accuracy: 0.9766\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 0.0675 - val_accuracy: 0.9766\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 0.0684 - val_accuracy: 0.9766\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.0686 - val_accuracy: 0.9766\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0692 - val_accuracy: 0.9766\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.0692 - val_accuracy: 0.9766\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.0699 - val_accuracy: 0.9766\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.0701 - val_accuracy: 0.9766\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.0698 - val_accuracy: 0.9766\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0707 - val_accuracy: 0.9766\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9975 - val_loss: 0.0732 - val_accuracy: 0.9766\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 0.0739 - val_accuracy: 0.9766\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.0751 - val_accuracy: 0.9766\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.0749 - val_accuracy: 0.9766\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 0.0756 - val_accuracy: 0.9766\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.0773 - val_accuracy: 0.9766\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.0788 - val_accuracy: 0.9766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0899808650>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_qbPYocYlzT",
        "outputId": "fb165302-f6cb-4b0b-b69a-5645b6d6f44d"
      },
      "source": [
        "# Compute predictions of X_test, here it is a 2 dimensional array: for each datapoint we get the probability of \n",
        "# it belonging to class 0 and to class 1. Note: compare the output to the previous yhat. Previously with 1 output neuron, \n",
        "#we got the prob only for class 1.  \n",
        "yhat = model.predict(X_test)\n",
        "yhat"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.95391849e-02, 9.80460823e-01],\n",
              "       [1.00000000e+00, 4.18655692e-12],\n",
              "       [1.00000000e+00, 1.47374335e-08],\n",
              "       [6.29030546e-05, 9.99937057e-01],\n",
              "       [9.27261226e-06, 9.99990702e-01],\n",
              "       [1.00000000e+00, 6.60413752e-28],\n",
              "       [1.00000000e+00, 6.54429515e-22],\n",
              "       [9.99932170e-01, 6.77804637e-05],\n",
              "       [7.57163405e-01, 2.42836580e-01],\n",
              "       [4.34116737e-05, 9.99956608e-01],\n",
              "       [4.24893051e-02, 9.57510769e-01],\n",
              "       [9.99961972e-01, 3.80745587e-05],\n",
              "       [1.54742191e-03, 9.98452544e-01],\n",
              "       [9.99711096e-01, 2.88920564e-04],\n",
              "       [3.23613858e-05, 9.99967694e-01],\n",
              "       [9.99999166e-01, 8.16380066e-07],\n",
              "       [6.33589661e-05, 9.99936581e-01],\n",
              "       [4.51023652e-06, 9.99995470e-01],\n",
              "       [5.50071718e-07, 9.99999404e-01],\n",
              "       [1.00000000e+00, 3.45875607e-16],\n",
              "       [3.04132774e-02, 9.69586670e-01],\n",
              "       [2.48600822e-03, 9.97514009e-01],\n",
              "       [1.00000000e+00, 1.00184445e-22],\n",
              "       [1.08735039e-04, 9.99891281e-01],\n",
              "       [3.48434638e-04, 9.99651551e-01],\n",
              "       [1.90698302e-05, 9.99980927e-01],\n",
              "       [2.14848878e-05, 9.99978542e-01],\n",
              "       [1.39737350e-03, 9.98602688e-01],\n",
              "       [9.56545409e-04, 9.99043405e-01],\n",
              "       [1.00000000e+00, 6.49482977e-14],\n",
              "       [2.52377969e-04, 9.99747574e-01],\n",
              "       [1.39559434e-05, 9.99986053e-01],\n",
              "       [2.19948997e-04, 9.99780118e-01],\n",
              "       [9.02043481e-04, 9.99097943e-01],\n",
              "       [3.04042442e-05, 9.99969602e-01],\n",
              "       [1.26939500e-04, 9.99873042e-01],\n",
              "       [9.81027842e-01, 1.89722329e-02],\n",
              "       [1.04889681e-04, 9.99895096e-01],\n",
              "       [1.00000000e+00, 1.75126039e-10],\n",
              "       [1.51744848e-02, 9.84825552e-01],\n",
              "       [2.48255856e-05, 9.99975204e-01],\n",
              "       [1.00000000e+00, 2.74092322e-08],\n",
              "       [4.58079230e-05, 9.99954224e-01],\n",
              "       [2.40658032e-04, 9.99759376e-01],\n",
              "       [4.50532250e-02, 9.54946816e-01],\n",
              "       [1.72265675e-02, 9.82773423e-01],\n",
              "       [3.87590035e-06, 9.99996066e-01],\n",
              "       [1.91255391e-03, 9.98087466e-01],\n",
              "       [1.31193697e-02, 9.86880660e-01],\n",
              "       [2.35785083e-05, 9.99976397e-01],\n",
              "       [1.00000000e+00, 1.15316472e-10],\n",
              "       [1.00000000e+00, 6.96645618e-19],\n",
              "       [3.12099338e-01, 6.87900662e-01],\n",
              "       [4.45554182e-02, 9.55444634e-01],\n",
              "       [1.27331268e-05, 9.99987245e-01],\n",
              "       [6.74696348e-04, 9.99325275e-01],\n",
              "       [2.79546894e-05, 9.99971986e-01],\n",
              "       [1.00000000e+00, 9.56274195e-28],\n",
              "       [9.99948621e-01, 5.13879386e-05],\n",
              "       [2.81810321e-06, 9.99997139e-01],\n",
              "       [1.43500802e-03, 9.98565018e-01],\n",
              "       [1.00000000e+00, 3.17899638e-17],\n",
              "       [1.00000000e+00, 4.41519042e-21],\n",
              "       [2.59109512e-02, 9.74089026e-01],\n",
              "       [4.29679436e-04, 9.99570310e-01],\n",
              "       [9.19748768e-02, 9.08025086e-01],\n",
              "       [1.00000000e+00, 1.06546589e-14],\n",
              "       [1.00000000e+00, 3.68806371e-26],\n",
              "       [3.41961073e-04, 9.99657989e-01],\n",
              "       [1.07255392e-03, 9.98927414e-01],\n",
              "       [9.99999881e-01, 1.46678943e-07],\n",
              "       [1.00000000e+00, 4.53543336e-08],\n",
              "       [6.09132461e-04, 9.99390841e-01],\n",
              "       [1.00000000e+00, 2.26948114e-08],\n",
              "       [8.43629605e-05, 9.99915600e-01],\n",
              "       [2.09215970e-04, 9.99790847e-01],\n",
              "       [2.82574054e-02, 9.71742630e-01],\n",
              "       [9.53848064e-01, 4.61519510e-02],\n",
              "       [3.66570839e-06, 9.99996305e-01],\n",
              "       [1.43915982e-04, 9.99856114e-01],\n",
              "       [9.99999762e-01, 2.76952505e-07],\n",
              "       [1.06674270e-05, 9.99989390e-01],\n",
              "       [9.74740863e-01, 2.52591204e-02],\n",
              "       [1.00000000e+00, 3.26636721e-21],\n",
              "       [9.99939561e-01, 6.04320194e-05],\n",
              "       [1.00000000e+00, 4.14305153e-11],\n",
              "       [1.00000000e+00, 9.27604348e-13],\n",
              "       [1.00000000e+00, 3.61022723e-09],\n",
              "       [2.82148576e-05, 9.99971747e-01],\n",
              "       [1.26368040e-03, 9.98736322e-01],\n",
              "       [8.73688201e-04, 9.99126375e-01],\n",
              "       [8.52892697e-01, 1.47107333e-01],\n",
              "       [7.78848818e-03, 9.92211580e-01],\n",
              "       [3.08046612e-04, 9.99691963e-01],\n",
              "       [1.59553092e-04, 9.99840379e-01],\n",
              "       [1.67822891e-05, 9.99983191e-01],\n",
              "       [1.00000000e+00, 1.76651188e-13],\n",
              "       [1.00000000e+00, 1.25787397e-16],\n",
              "       [1.58948728e-06, 9.99998450e-01],\n",
              "       [9.99999881e-01, 6.60586679e-08],\n",
              "       [9.99998808e-01, 1.15400189e-06],\n",
              "       [5.62393403e-08, 1.00000000e+00],\n",
              "       [1.00000000e+00, 2.79241165e-14],\n",
              "       [1.00000000e+00, 1.15220899e-09],\n",
              "       [2.09726710e-02, 9.79027390e-01],\n",
              "       [1.86698303e-01, 8.13301682e-01],\n",
              "       [1.77869899e-03, 9.98221338e-01],\n",
              "       [1.00000000e+00, 6.33368772e-22],\n",
              "       [2.16883700e-03, 9.97831166e-01],\n",
              "       [3.59639414e-02, 9.64036047e-01],\n",
              "       [1.00000000e+00, 1.33925058e-08],\n",
              "       [1.18157259e-04, 9.99881864e-01],\n",
              "       [1.14221452e-02, 9.88577843e-01],\n",
              "       [1.00000000e+00, 5.36160477e-24],\n",
              "       [9.87473965e-01, 1.25260865e-02],\n",
              "       [1.00000000e+00, 6.31862281e-24],\n",
              "       [5.18248441e-07, 9.99999523e-01],\n",
              "       [4.55899052e-02, 9.54410076e-01],\n",
              "       [1.69280156e-05, 9.99983072e-01],\n",
              "       [1.00000000e+00, 1.85853177e-12],\n",
              "       [1.60839912e-02, 9.83915985e-01],\n",
              "       [2.59260614e-05, 9.99974132e-01],\n",
              "       [4.95548244e-04, 9.99504447e-01],\n",
              "       [1.00000000e+00, 7.53141716e-11],\n",
              "       [1.64138675e-02, 9.83586133e-01],\n",
              "       [1.00000000e+00, 5.03439961e-16],\n",
              "       [1.00000000e+00, 2.36182410e-11],\n",
              "       [2.02140058e-04, 9.99797881e-01],\n",
              "       [1.44348349e-04, 9.99855638e-01],\n",
              "       [1.00000000e+00, 1.70532593e-15],\n",
              "       [1.00000000e+00, 1.27704472e-23],\n",
              "       [1.00000000e+00, 2.22219441e-17],\n",
              "       [1.97522994e-03, 9.98024821e-01],\n",
              "       [2.96221318e-04, 9.99703705e-01],\n",
              "       [2.11383076e-03, 9.97886121e-01],\n",
              "       [1.00000000e+00, 4.45346121e-10],\n",
              "       [3.81489962e-01, 6.18510067e-01],\n",
              "       [1.79960299e-03, 9.98200417e-01],\n",
              "       [7.97934532e-02, 9.20206487e-01],\n",
              "       [1.00000000e+00, 1.30907740e-09],\n",
              "       [1.20689324e-03, 9.98793125e-01],\n",
              "       [1.00000000e+00, 4.08237543e-19],\n",
              "       [5.79273149e-07, 9.99999404e-01],\n",
              "       [6.34587309e-07, 9.99999404e-01],\n",
              "       [1.00000000e+00, 7.61408625e-09],\n",
              "       [5.42144553e-05, 9.99945760e-01],\n",
              "       [1.00000000e+00, 2.91181772e-14],\n",
              "       [1.00000000e+00, 9.54421902e-15],\n",
              "       [9.97149885e-01, 2.85013323e-03],\n",
              "       [7.52795677e-05, 9.99924660e-01],\n",
              "       [9.99625802e-01, 3.74164083e-04],\n",
              "       [7.03236356e-06, 9.99992967e-01],\n",
              "       [2.78023748e-07, 9.99999762e-01],\n",
              "       [1.09517444e-02, 9.89048302e-01],\n",
              "       [4.24238067e-04, 9.99575794e-01],\n",
              "       [1.00000000e+00, 2.71102724e-34],\n",
              "       [1.00000000e+00, 1.31949243e-10],\n",
              "       [3.30305484e-05, 9.99966979e-01],\n",
              "       [1.14405586e-03, 9.98855948e-01],\n",
              "       [1.44374064e-06, 9.99998569e-01],\n",
              "       [7.81789204e-05, 9.99921799e-01],\n",
              "       [7.35737149e-06, 9.99992609e-01],\n",
              "       [5.99520972e-05, 9.99940038e-01],\n",
              "       [1.21352205e-04, 9.99878645e-01],\n",
              "       [9.40215588e-01, 5.97844608e-02],\n",
              "       [3.91914509e-05, 9.99960780e-01],\n",
              "       [4.75046400e-05, 9.99952435e-01],\n",
              "       [3.39292079e-01, 6.60707891e-01],\n",
              "       [1.62223532e-05, 9.99983788e-01],\n",
              "       [9.99992251e-01, 7.68989503e-06],\n",
              "       [1.95542088e-04, 9.99804437e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQX8vT_Ba7Oo",
        "outputId": "86937fb0-0def-4867-c017-b34c33f42e5d"
      },
      "source": [
        "# Finding the most probable class\n",
        "yhat_c = np.argmax(yhat, axis=1)\n",
        "print(yhat_c)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
            " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0\n",
            " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN4rFkDaf6ra",
        "outputId": "f03a3662-bf6c-4d4d-dd83-0a845af719d9"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(171, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN-k2DKagSS0"
      },
      "source": [
        "true_label = np.argmax(y_test,axis = 1)\n"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySv8R9k8eCMG",
        "outputId": "66f9873e-248c-42a5-81d0-11f069d0047c"
      },
      "source": [
        "\n",
        "cm = confusion_matrix(true_label,yhat_c)\n",
        "\n",
        "score = accuracy_score(true_label,yhat_c)\n",
        "print(cm)\n",
        "print('score is:',score)\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 62   1]\n",
            " [  0 108]]\n",
            "score is: 0.9941520467836257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7haMDK_gbaX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psLQ4es7gtzA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
